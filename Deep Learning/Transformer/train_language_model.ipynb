{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor\n",
    "from src.core.utils import context_manager\n",
    "from src.architectures.transformer import Tokenizer, Transformer, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.2 # The dropout rate\n",
    "train_val_split = 0.9 # 90% of the data will be used for training, 10% for validation\n",
    "batch_size = 32 # The number of samples to use for each batch\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 1e-3 # The learning rate for the optimizer\n",
    "epochs = 50 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "eval_iters = 10 # The number of iterations to evaluate the model\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = Tensor(np.array(encoded_text), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data loader\n",
    "data_loader = DataLoader(\n",
    "    data = data, \n",
    "    train_val_split = train_val_split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = Transformer(\n",
    "    name = \"Language Model\",\n",
    "    vocab_size = vocab_size,\n",
    "    n_embed = n_embed,\n",
    "    n_attention_heads = n_attention_heads,\n",
    "    sequence_length = sequence_length,\n",
    "    n_decoder_blocks = n_decoder_blocks,\n",
    "    dropout = dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    x, _ = data_loader.get_batch(\n",
    "        batch_size = batch_size,\n",
    "        sequence_length = sequence_length\n",
    "    )\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (Transformer) [output_shape=(32, 1024), params=11526400]\n",
      "└── language_model.decoder (Decoder) [output_shape=(32, 1024), params=11526400]\n",
      "    ├── decoder.embedding (Embedding) [output_shape=(32, 384), params=393216]\n",
      "    ├── decoder.positional_embedding (Embedding) [output_shape=(384), params=98304]\n",
      "    ├── decoder.decoder_blocks[0].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[0].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[0].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.decoder_blocks[1].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[1].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[1].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.decoder_blocks[2].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[2].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[2].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.decoder_blocks[3].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[3].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[3].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.decoder_blocks[4].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[4].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[4].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.decoder_blocks[5].decoder_block (DecoderBlock) [output_shape=(32, 256, 384), params=1773312]\n",
      "    │   ├── decoder_block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   ├── decoder_block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "    │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │   │   ├── decoder_block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "    │   │   └── decoder_block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "    │   ├── decoder_block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    │   └── decoder.decoder_blocks[5].decoder_block.attention_heads (MultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "    │       ├── multi_head_attention.heads[0].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[1].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[2].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[3].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[4].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.heads[5].single_head_attention (SingleHeadAttention) [output_shape=(32, 256, 384), params=73728]\n",
      "    │       │   ├── single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   ├── single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "    │       │   └── single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "    │       ├── multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "    │       └── decoder.decoder_blocks[5].decoder_block.attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "    ├── decoder.layer_norm (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "    └── decoder.output_layer (Dense) [output_shape=(32, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 7.0785\n",
      "Epoch 2/50 - Train Loss: 6.4140\n",
      "Epoch 3/50 - Train Loss: 5.4272\n",
      "Epoch 4/50 - Train Loss: 5.0996\n",
      "Epoch 5/50 - Train Loss: 4.7485\n",
      "Epoch 6/50 - Train Loss: 4.5417\n",
      "Epoch 7/50 - Train Loss: 4.4484\n",
      "Epoch 8/50 - Train Loss: 4.4168\n",
      "Epoch 9/50 - Train Loss: 4.3065\n",
      "Epoch 10/50 - Train Loss: 4.2797\n",
      "Epoch 11/50 - Train Loss: 4.2845\n",
      "Epoch 12/50 - Train Loss: 4.2444\n",
      "Epoch 13/50 - Train Loss: 4.2433\n",
      "Epoch 14/50 - Train Loss: 4.2342\n",
      "Epoch 15/50 - Train Loss: 4.1823\n",
      "Epoch 16/50 - Train Loss: 4.1533\n",
      "Epoch 17/50 - Train Loss: 4.1858\n",
      "Epoch 18/50 - Train Loss: 4.0968\n",
      "Epoch 19/50 - Train Loss: 4.0679\n",
      "Epoch 20/50 - Train Loss: 4.0860\n",
      "Epoch 21/50 - Train Loss: 4.0566\n",
      "Epoch 22/50 - Train Loss: 4.0444\n",
      "Epoch 23/50 - Train Loss: 4.0568\n",
      "Epoch 24/50 - Train Loss: 3.9951\n",
      "Epoch 25/50 - Train Loss: 4.0132\n",
      "Epoch 26/50 - Train Loss: 4.0193\n",
      "Epoch 27/50 - Train Loss: 4.0037\n",
      "Epoch 28/50 - Train Loss: 3.9421\n",
      "Epoch 29/50 - Train Loss: 4.0004\n",
      "Epoch 30/50 - Train Loss: 3.9378\n",
      "Epoch 31/50 - Train Loss: 3.9437\n",
      "Epoch 32/50 - Train Loss: 3.9175\n",
      "Epoch 33/50 - Train Loss: 3.8939\n",
      "Epoch 34/50 - Train Loss: 3.8878\n",
      "Epoch 35/50 - Train Loss: 3.8782\n",
      "Epoch 36/50 - Train Loss: 3.8945\n",
      "Epoch 37/50 - Train Loss: 3.8440\n",
      "Epoch 38/50 - Train Loss: 3.8689\n",
      "Epoch 39/50 - Train Loss: 3.8310\n",
      "Epoch 40/50 - Train Loss: 3.8407\n",
      "Epoch 41/50 - Train Loss: 3.8751\n",
      "Epoch 42/50 - Train Loss: 3.8133\n",
      "Epoch 43/50 - Train Loss: 3.8093\n",
      "Epoch 44/50 - Train Loss: 3.7878\n",
      "Epoch 45/50 - Train Loss: 3.8151\n",
      "Epoch 46/50 - Train Loss: 3.7650\n",
      "Epoch 47/50 - Train Loss: 3.7957\n",
      "Epoch 48/50 - Train Loss: 3.7875\n",
      "Epoch 49/50 - Train Loss: 3.7863\n",
      "Epoch 50/50 - Train Loss: 3.8185\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "language_model.fit(\n",
    "    data_loader = data_loader,\n",
    "    epochs = epochs, \n",
    "    lr = learning_rate,\n",
    "    batch_size = batch_size,\n",
    "    eval_iters = eval_iters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o uo a stell che ma di peaio al mo quanaco di cia poggitorssogiuaticote alca grie e\n",
      "nbmar le rucua.\n",
      "nder llicor.\n",
      "ombto stpiattcorin che ciascunr qucall o motro om fuo e in un bete mi mimi tra e le la la e lisca che de che stgue manorarmansi suanzlore vi, 'a e e diar,\n",
      "mo tutte  e e 'agngria erali fo nella che chgia mi'risar"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.generate(context, max_new_tokens=200, stream=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
