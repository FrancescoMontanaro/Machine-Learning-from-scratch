{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.core.utils import data_analysis, data_processing, context_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.1 # The dropout rate\n",
    "maximum_samples = 19840 # The maximum number of samples to use from the dataset\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 32 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 1 # The number of steps to accumulate gradients before updating the model\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 1e-3 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "epochs = 1 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, seq_length: int, num_samples: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - seq_length: int, length of input sequences\n",
    "    - num_samples: int, number of sequences to generate\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor], input sequences and targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y = [], []\n",
    "    n = len(input_data)\n",
    "    \n",
    "    # Iterate over the number of samples to create\n",
    "    for _ in range(num_samples):\n",
    "        # Generate a random starting index for the sequence\n",
    "        start_idx = np.random.randint(0, n - seq_length - 1)\n",
    "        \n",
    "        # Extract the input and target sequences\n",
    "        # The input sequence is the current sequence of length seq_length\n",
    "        # The target sequence is the next sequence of length seq_length (shifted by one)\n",
    "        input_sequence = input_data[start_idx : start_idx + seq_length]\n",
    "        target_sequence = input_data[start_idx + 1 : start_idx + seq_length + 1]\n",
    "        \n",
    "        # Aggiungi le sequenze alle liste\n",
    "        X.append(input_sequence)\n",
    "        y.append(target_sequence)\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return Tensor(np.array(X, dtype=np.int32)), Tensor(np.array(y, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences from the encoded text data\n",
    "X, y = build_sequences(data, sequence_length, maximum_samples)\n",
    "\n",
    "# Shuffle the data\n",
    "X_shuffled, y_shuffled = data_processing.shuffle_data((X, y))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (16071, 256) (16071, 256)\n",
      "Validation set: (1785, 256) (1785, 256)\n",
      "Testing set: (1984, 256) (1984, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data((X_shuffled, y_shuffled), train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape(), y_train.shape())\n",
    "print('Validation set:', X_valid.shape(), y_valid.shape())\n",
    "print('Testing set:', X_test.shape(), y_test.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    input_dim = vocab_size,\n",
    "    sequence_length = sequence_length,\n",
    "    n_embed = n_embed,\n",
    "    return_sequence = True,\n",
    "    n_attention_heads = n_attention_heads,\n",
    "    n_decoder_blocks = n_decoder_blocks,\n",
    "    dropout = dropout,\n",
    "    positional_encoding_type = 'learned'\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy(from_sequence=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(32, 256, 1024), params=11526400]\n",
      "└── language_model.modules (ModuleList) [output_shape=(32, 256, 1024), params=11526400]\n",
      "    └── module_list.0 (Decoder) [output_shape=(32, 256, 1024), params=11526400]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(32, 256, 384), params=393216]\n",
      "        ├── decoder.positional_encoding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=10639872]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.4.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.4.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   └── module_list.5 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │       │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │       │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │       │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       └── module_list.5.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │           ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │           │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │           └── module_list.5.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(32, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 --> loss: 3.1886 - accuracy: 0.33335 | Valid loss: 3.0003 - Valid accuracy: 0.34247                        \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = language_model.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_valid = X_valid,\n",
    "    y_valid = y_valid,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    metrics = [metrics.accuracy],\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8 - 2240.97 ms/step"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions = language_model(X_test[:256], batch_size=batch_size, verbose=True)\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions.data, axis=1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:256], predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o, qui lor che tal scuomi;\n",
      "con vallil ha di di della\n",
      "prende cera , sito tugio luce me di discrimai.\n",
      "pugnor ripa e presenza gran la e ntra che P, la al me la sempre ina sazi chee 'io ro\n",
      "connon per ai virquella s'ambua in secondo per ve scendel'acqui naturammo cielo la a lucesi daldi parere ia queston dell'imagino tra fire famir cher al"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
