{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.core.utils import data_analysis, data_processing, context_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.2 # The dropout rate\n",
    "maximum_samples = 19840 # The maximum number of samples to use from the dataset\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 32 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 1 # The number of steps to accumulate gradients before updating the model\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 1e-3 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "epochs = 1 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, seq_length: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - target_data: np.ndarray, target values (aligned with input_data)\n",
    "    - seq_length: int, length of input sequences\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor], input sequences and targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Iterate over the input data to create sequences\n",
    "    for i in range(seq_length, len(input_data)):\n",
    "        # Append the sequence of input and the corresponding target\n",
    "        X.append(input_data[i-seq_length:i])\n",
    "        y.append(input_data[i-seq_length+1:i+1])\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return Tensor(np.array(X, dtype=np.float32)), Tensor(np.array(y, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences from the encoded text data\n",
    "X, y = build_sequences(data, sequence_length)\n",
    "\n",
    "# Shuffle the data\n",
    "X_shuffled, y_shuffled = data_processing.shuffle_data((X, y))[0]\n",
    "\n",
    "# Take only a subset of samples for faster training\n",
    "X_shuffled = X_shuffled[:maximum_samples]\n",
    "y_shuffled = y_shuffled[:maximum_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (16071, 256) (16071, 256)\n",
      "Validation set: (1785, 256) (1785, 256)\n",
      "Testing set: (1984, 256) (1984, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data((X_shuffled, y_shuffled), train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape(), y_train.shape())\n",
    "print('Validation set:', X_valid.shape(), y_valid.shape())\n",
    "print('Testing set:', X_test.shape(), y_test.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    input_dim = vocab_size,\n",
    "    sequence_length = sequence_length,\n",
    "    n_embed = n_embed,\n",
    "    return_sequence = True,\n",
    "    n_attention_heads = n_attention_heads,\n",
    "    n_decoder_blocks = n_decoder_blocks,\n",
    "    dropout = dropout\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(32, 256, 1024), params=11526400]\n",
      "└── language_model.modules (ModuleList) [output_shape=(32, 256, 1024), params=11526400]\n",
      "    └── module_list.0 (Decoder) [output_shape=(32, 256, 1024), params=11526400]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(32, 256, 384), params=393216]\n",
      "        ├── decoder.positional_embedding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=10639872]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.4.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.4.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   └── module_list.5 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │       │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │       │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │       │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       └── module_list.5.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │           ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │           │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │           └── module_list.5.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(32, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 --> loss: 3.2075 - accuracy: 0.33205 | Valid loss: 3.0139 - Valid accuracy: 0.34199                        \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = language_model.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_valid = X_valid,\n",
    "    y_valid = y_valid,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    "    metrics = [metrics.accuracy],\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAGICAYAAABGJ/YJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAREhJREFUeJzt3QmcTfUf//HPWGaYCWMZsiuUnURCZIsSQlIqS2WJZM2abIVsiVZthB/ZIxVSqCwpS0lCMpYR2Xcj3P/j8/3/z/3fO3PvrHfm3jvn9Xw8TjP3nHPPcs+dvO/3fr7fE+JwOBwCAAAA2FQmfx8AAAAA4E8EYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgDIQDp16iQhISHpvt+RI0ea/UZHRyf7ufocfa5uAwD8gUAMINVKlChhAk1i08yZM322v3r16gVVYAwkTz/9tISGhsqJEyc8Lr9w4YJERETIq6++mqr9+PO11v3q/tObvsd134sWLUr3fQNIuSypeC4AGF988YXExsY6H48aNUpWrFgha9askVy5cjnn33bbbT7bnwa6lNBWyJ49e4qdPfPMM/K///3PTH369Im3fPHixXLlyhUTnFMjrV/rU6dOme0//PDD8Y71559/lnz58qXZvgFkLARiAKlWsWJFt8d58+Y1PytXrpykUHL58mUJDw9P8f6S27qsk501aNBAihcvLjNmzPAYiGfPni21a9dO9QeYtH6ttSX7s88+kzvvvDPesmrVqqXZfgFkPJRMAEh3VsnDd999J1WqVJGcOXM6l40ZM0aqV68ukZGRZmrWrJkcOXLE4/M9fUW+ZcsWuf/++81X/mXKlJFVq1Yl+jW+bku3+c8//8hTTz1l9nvrrbfKhAkT4h37Dz/8IDVr1pTs2bObwPj22287n58Y/Rq9cePGUqBAAfMBQEObbs/T8Z0/f15eeOEFiYqKMh8w+vbtKzdv3nRbd/v27WbfeiyFCxeWESNGyI0bNxI9Dt1+hw4d5LfffpNt27a5LdPXet26ddK+fXvnPL1OjzzyiNmH7qtcuXKydOnSRPfj6bXW4xs+fLhzW3r8O3bsiPdcLefo1auXuYb6Wun10Nfj+vXrZrkeoxXY9RsJ3c+9996bYMnEsWPH5NlnnzWvf1hYmAnS48aNi/eaWe+vvXv3mvdfjhw5zAcI/aDgK6tXr5Y6deqY9+ktt9xiPqR8//338dabPn26Oc5s2bKZD5f6PnB16NAhadWqlXmP6Dq67p49e3x2nIBdEIgB+IV2pOratav07t3bhAPX0NK/f3/58ssv5b333pP169fLwIEDk7RNDYga3Fq3bm2er4HriSeeMC2Jibl48aLUrVvXhKXPP//cBNdBgwa5BVb9Gv6BBx6Qa9euyfz5800YXr58uWzcuDHJ5/zYY4+Z52qg1DKTxx9/3OO6uh89bl1XQ9ybb75pShwsBw4cMKHt7NmzMm/ePPnoo49k586dZv2ksMKqthK7mjNnjmTNmlXatm3rdtx6PJ9++ql89dVXkj9/fvPBQfedXNoirR96nnvuOVm5cqUJc57KKk6fPm3C4sSJE03pjYbhd999Vz755BOz/O677zavverSpYu5NgnVqJ85c0Zq1aplPiC9/vrrZt/62ms491RrrB8M6tevLzVq1DDlPxrM9Tro655aS5YskYceekhy584tCxculLlz50rmzJmlYcOGbh/gvv32W3n++eflySefNB9KPvjgg3gt33odNLjre0Ofq69lcr5tAfD/OADAxzp27OjQ/72cOHHC4/LixYs7smfP7ti9e3ei26pbt66jTJky8Z5///33u83T/YWHhzu2bdvmnDd16lQz/6effop3bK50Wzrv/fffd8779ddfzbzx48c75zVs2NARFhbmOH78uHPejRs3HFWqVDHHlFzDhw83+zh27Fi84xs8eLBz3rlz58y87t27O+c999xzjkyZMjmio6PdttmqVat45+eNnneePHkcV69edc4rV66c49FHH03weZ988onZx+bNm53zRowYYeYdOHAg3rlYDh48aI752Wefddue9VrrNry5efOmWef55593ztN9eXueztf9W1555RUz7/vvv3dbb+DAgfHeI3ot9Ti/+uor57xly5aZ9ebPn5/gazNjxgyz3sKFC72eR7FixRylS5c27x3LtWvXHIULF3aULVvWOW/ixIlmW//884/X/UVERDi6deuW4DEBSBwtxAD84p577jGtbnFpK6e2ehUtWtR0nNOvkbWDV1I8+uijctdddzkfW6UYWqOcGN1ft27dvD5XW3O1tVpbDbWF1JIpUya3joMJ0TIAbf0uW7asab0ePXq0me/p/LQVNaHz+Oabb6RChQrmq3xXruUnidGWUW2JtVpatXzijz/+cCuXsFrPtSxBa8K11VZbSr0dd0K0xVPLPrQMISnHvGzZMmnSpIkpG8mSJUuK9un6emkpjJYpuGrevLlzuSutodZW3JS8lxKirbla5qAdAfW9Y9FW+QcffFB2794tMTExZp4+1r8BPZYPP/xQrl69Gm97+o2IthzrtdS/HQApQyAGEDC2bt1qvqLetGmTvPLKKyYM61fjSeUaMJIrsefqiAZav1qkSJEUbV/LH7T2WMOLfgWuX9m7BvDkHo/WO2t5R2po+YbWr1plE1ojq7WoTZs2da6j9bVaPvLaa6+ZnxpSNRynhB6zSspxa3lEy5YtzQcRLZ3R2vDUOHnypAnWcVnzdLmv3kuJHYfrfhM6Fv3As3btWlM7rOVFWjOt5RautIRES4p0ZBD9wKKlLikpZQHsjlEmAASMqVOnmgCkHaaKFStm5mlgixtW/EFDiYakS5cupej5Wiu6f/9+U6OrLeBKw05K5cmTx7Tcpoa29moonjVrlhw+fNjUImtdrbZWWrRVXD+gaCB++eWXzby4nRyTc8wqKcetdb7akq4tt67Hk5rr56mz2b///us1oKYFa9QVT+9pT8eidc8//fSTuQb6AUoD765du5wja2jnQH2t9NpMmTLFdKzUeb7sAAjYAS3EAAKGfn2vX2tbYVhLQc+dOxdvdAV/0K+uNaBt3rzZHJdFv97WoJVYi6KeW9wh47Sjl0rJ+WnroX5F7tphUL/OT+7X5vpVu7YCd+zYUY4fPx6vXMKXx63HrOJ2QtTAF5fuV0tqrDDsaZ86qoLSETkS06hRI7ONDRs2uM3XFm9reXq44447zPtbO326not21NRvDfQ9VqhQoXjP028X9EYpeq00EMelI2FoB0EdteXXX39N8/MAMhpaiAEEDB0uTYOCtnbpMFTaYqyBU8sVdOSHFi1apNlX2Umhx6XlDlpDq8OW/fXXX2ZoNg1mid0oREewsLYxYMAAM3KBNSKEtubpaBv6YSCpdBtaY9quXTszcoPWJ2tLoesNUpJCa2pLlixpWqtLlSrlNnSZ0hIWbXHUmmYNXRpetZxBLViwQMqXL5/k0o377rvPbH/SpElSsGBBE3g1kOooEp7eC19//bVpUdeWbC2h0XKOH3/80YwmorXiOhSblrDoCAu6vtZTayD0RIcr09dZW8DHjh1rasa1pllH79BrqjXtvqQfTOJeTz1+Pe7Jkyebll6teddWXw3D+l7XDyQ6WohFh4TTDwZ6blpzriNuaL26hmOlHxZ1GzqSigZtfV10v1qnDiCZktDxDgB8PspE3FEiVGxsrKNr166OXLlyOUqUKOGYMmWKY//+/aZXflRUlOPUqVNenx93VAHXHv9r166Nd2yudFtxR4nwNoKBjlyhx6OjTdx9991m2zVr1jRTYt555x1HwYIFHblz53a88MILjpMnTzrq1atnRgpYuXKl1+Pzdn4ffvih4/bbb3eEhoY6Klas6Fi6dKnX5yfk1VdfNc8ZNWqUx+WLFy923HbbbY5bbrnF8dRTTzmOHj3qePLJJx3ZsmVzfPTRR0keZUIdOXLE0bJlSzMiSGRkpKNTp06O7du3x3utDx8+7HjggQfMevo66+vz+eefO3LkyOGoX7++c70ffvjBUalSJbOe6+vj6fWKiYlxdOjQwZEvXz5H1qxZHXfccYdjzJgxjv/++89tPU/vL73Ouk19TyXEes95mnSUEouOYKHvGX0N9frrObm+T5Vez9q1a5u/Bz3vBg0auI2GoaODPP300+ZvRd+PetzDhg0zI1YASJ4Q/U9yQzQAQJytdNoyqXXB77zzjr8PBwCQApRMAEASae2mdo7TmyNoBzEt59Cvv/Urb083lwAABAcCMQAkkXZg07vq6R3qtGVYx6bVUQD0bnbaGQoAEJwomQAAAICtMewaAAAAbI1ADAAAAFsjEAMAAMDW6FSXQnqHoaNHj5qB6kNCQvx9OAAAAIhDu8pph2i9A2RCN3YiEKeQhmG90xEAAAAC2+HDh82dLb0hEKeQtgxbL7AOvQQAAIDAcv78edOAaeU2bwjEKWSVSWgYJhADAAAErsTKW+lUBwAAAFsjEAMAAMDWCMQAAACwNWqIAQBAurtx44b8999//j4MBLnMmTNLlixZUj0ELoEYAACkq4sXL8qRI0fMGLFAaoWHh0vBggUlNDQ0xdsgEAMAgHRtGdYwrCEmKiqKm1shxfQD1bVr1+TEiRNy4MABKV26dII330gIgRgAAKQbLZPQIKNhOHv27P4+HAS57NmzS9asWeXgwYMmHGfLli1F26FTHQAASHe0DMNXUtoq7LYNnxwJAAAAEKQIxAAAALA1AjEAAEACSpQoYUo8vE2dOnVK8bZnzpyZ7PIR3V+9evUkPc575MiRYgd0qgMAAEjAb7/9Jjdv3jS/r1q1Sp544gn59ddfpVixYmZeaob7evLJJ6Vly5bJes67777rPB74BoEYAAAgATlz5nT+HhER4ZwXGRnp9Tk6ksb169fNCAgJ0TCd3ECtQ9bBtyiZAAAAfqP35rh0yT+Tr+8LoiUGL7/8snTv3l1y5MghP/30k1y+fFmee+45KV68uBki7K677pJt27Z5LZlYt26debxx40Zp3ry5CeA1a9Y0Yzd7K5nQsgbdtz6natWqcsstt8hTTz1lxny2HD58WJo0aWKGJatYsaKMGzfO7Of3339P8vmdP3/enEvevHlNKNft7dmzx7lc99ejRw+zXM+1TZs2bs8fPXq03HrrrRIWFiY1atSQQEIgBgAAfnP5ssgtt/hn0n372gcffCAFChSQP//8U+6++24z7nKlSpVMqYWGRw2rgwYNSnQ7HTt2lHbt2smuXbvk5MmTMnbs2ATXP336tLz44ovy1ltvybfffiufffaZLF682Ln80UcflXPnzsn27dtlxowZsmTJkmSf23PPPSc///yzORctI8mTJ488+OCDcvXqVbNc97ls2TLZsGGDOddevXo5n6vzXn/9dfniiy/MTTQSO5/0RskEAACAjzRs2NCtI5q2lPbu3dv5uEGDBjJnzpxEtzNq1ChTX6zuuecet5ZYTzR4L1iwQEqWLGkea0us9Zzvv//eBFmdypYta+ZNmDDBHEtS7d+/XxYtWiQrV66UatWqmXnvvfee2c/cuXPl2WefNcE9NjbWnLPWV1s11kqXaQlJlixZpFChQmYKJLQQAwAAv9Fy2IsX/TOlRSlumTJl4s1bunSpaUnVsKpB1LWUwZtatWo5f9c65MSeo63SVhiO+5ydO3eaIKrlFJbkjmyxa9cu87Ny5crOeVpDraUg1rL27dtL/vz5pVy5cuZDgIZgy0MPPST33nuvKZXQkg+9s1wg8WsgXrNmjXlhtT4mV65cUqdOHdOk7s2WLVukWbNm5sXWi/DII494fEH1k4q+KXS7Wr9y6tQpt+X6Bhk6dKipcdFJf6e3JgAA6U9zmfZT88eUHjfL++STT0wW0TCoJQzdunWT9HblyhVTO+yLO7p56jxohWstodCSDK1P1tZqLRk5c+aMWaYdB9euXSsfffSRyXpaS/3XX39JoPBrINZQO3nyZNm3b59s2rTJXKi2bdt6Xf+XX36R+vXry48//mim48ePS4sWLdw+Na1fv166du0qU6dOld27d5tl1lcOFq1b0TelXhid9CuA8ePHp+m5AgAA+9GM0bRpU1NGUaVKlQRHpkgrt912m1y8eFFOnDjhnGf9ntSW4vLly5ufWjts0bB76NAh5zKlHea0dlhznS777rvvnMsyZ84sHTp0MJ0KtXxC640DhV9riK0aFKW1JK1bt5bBgweb1lpPn2K056KrMWPGSKNGjUygtr6imDRpkjzzzDOmJVm9//77UrhwYdmxY4d5I2pty7Rp08x8LXJX+klGt92/f/9UjSUIAADgqmjRovLNN9+Yel6tw9X64X///Veio6PNyBDpQQN5VFSUDBkyREaMGGFGv3jllVfMssSGhbPoN+/aaDlgwACzLe0cqCNqFCxY0HT+szrV6egT2jKso2VolrvzzjvNMu2Ipx3/ateubRosdfQNq545EAREDbE2t2/dulWmT59uPkEltUlfP4VYXwUofXG/+uor04rsWlOjL/jChQvNY71AWtPiuo4OXaJvTm1dBgAA8BUNoNowpyUCOgKFtorq4+TejCM1tJOb5iAtVShdurTJWxpmlQbbpPrwww9N2NUMpSWvOgybdrLTcgylDZrasFmqVCl57bXXTLlIhQoVnK3DEydONA2YnTt3Nt/Wa1APFCEOTaN+pC2z+gbRF1FbfPXTS1L17NnTFKprHbEWi2tL8R133GFqjatXr+5cT19wrWvRT2V6Mfv06SOXdABCF/qJRluO9SJ5oi3LOln0TaCf+nQIE9cBuwEAgHc6RJcOu6Vf41tBCulPs1ffvn3lwoULaVJbHCjvKc1r2k8tsbzm91dAB2nWADtlyhTT81IvTlKsXr3aFGZ//PHHJgwrqzdj3BdDH1vL9KenP0DXdTzRsgp9Qa1JwzAAAEAw0EZB/Tb+2LFjZlADbYTUW1AHexjOMOMQ58uXz0w6FIje1UVbaLUFV4fx8EbLHrSOZdasWWYYE4vWtChrgGiLllRYy/Rn3OVx1/FEW6779esXr4UYAAAg0GlZqNb/ah2v5het+3UdL9nu/B6IXenYdFrBoUXn3gKxfrrRuhttGda7rrjSmhytUdHbG7qWTGgvR2vsPd2u1hprz8jcuXM7e1pqSHYdQNpTvbJVswwAABBMtGQU3gVUO7l1RxVvYVhbZXUkCh3sOW4YtorGH374YTOUmuWff/4xt0+07qd9//33m5Zg13V0SBCdp8sAAABgL35tIZ43b54Z5kxbhrVDnJYkNGnSxHmnFb39obb6ammE0noXHQ1CB7U+e/asczvaQ9KqI9ah07QTnU46uoR2vNNbE2rvTqX70/HxtHelDgWitzrU3zVkM+QaAACA/fg1EGvPRr0hRkxMjGmh1RCrndcsWjrhetMNHTdPSxs0JLvS1l4dOk3VrVvXjDH8/PPPm1II3ebMmTPj1QPrvu+77z5TYqE38kjO6BYAAADIOPw+7FqwSuowHgAA4P9j2DX4WoYYdg0AAADwJwIxAAAAbI1ADAAAkADtoK8d9T3R2yBrJ/2k0P5OnTp1cj7W360+UN6UKFFCXnrppWQecfxtpPWYw+vWrZOQkBCJjo6WYBRQ4xADAAAEGr2j2zvvvCO//vqrVK5c2W3ZwoUL5bHHHkvRdt999125efOm+NLEiRPNKF3W/RfUb7/9xkhaiaCFGAAAIAG1a9c2d3f77LPP3ObraFbaMprSQBweHm6GjvWlgQMHmgDsSjuT0YExYQRiAADgPzrY1fVL/pmSONCWlgK0bdtW5s+f7zZ/6dKlcvvttztbjTds2CCNGjWSPHnymJENnnrqKXO/A2/ilkzowF86DKw+P1++fPLqq6/Ge47eqVdbfyMiIuTWW2+VSZMmuZVGqGeeecYcs4Z1TyUTOvLCc889J3nz5jWhvEmTJs6bo7mWP2zcuFGaN29u9lWzZk1zJ+Dk2LRpk9SqVcuEcT1WDeuur8fu3bvNhw29sZqer+vrqzdWe+ihh8wHhsjISJk8ebKkJUomAACA/9y4LLLAt62kSdb2okiWiCSXTWgo03si6A3FrHIJ60646sqVK+ZGX3ozML2XgoZjvR+CBuOkeO+990xNsrZE611733rrLTl06JDbOnojMp2vNzGbM2eOCZl6bEWKFDEtwxrEtbzjySef9Nr6rGFYA/CqVatM2HzllVfkwQcfNAHVtSW5Y8eOMmrUKLO/Bx54QMaOHWvKPJLi2LFj0rhxY+nSpYvMnTvX1Ba3b99eMmXKJK+//rpZR2+UpvXXixcvNjdec9338OHDzQcEPU69d0RsbKykJQIxAABAIqpVqyalSpUyYVUD8cmTJ82NwSZMmOBcRwOwRQNqoUKF5O+//07yPt544w1zszANkurtt9+WFStWuK2jIdXy6KOPyoABA8wYvLo/a5xdbfXVoOuJBvVFixbJypUrzTlZQfzWW281wfXZZ591rqthWIO1uueee9xakROjoVzDudY0603QtJVa7wzcp08fGTFihGkV1tdQW4Z10v270mU6vrCeR9wbsqUFAjEAAPCfzOH/t6XWX/tOhscff9zc/VaD65IlS0zI09Zgi978Ydq0abJs2TJzF97jx4+73XE3Idq6rGG1YsWKCa73119/mTIJLc84evSomZfUfahdu3aZn66dAyMjI02LtLXMouUOlqxZsyZ7PxUqVDBh2KL71JZePQc9Ty3j0FKUrVu3mrDcoUMHU6qhBg8ebD4Y3HHHHSb0v/DCC+YY0go1xAAAwH80AGnZgj+m/xe+kkpLEzTo/vDDD/HKJZTW286YMUMGDRok69evNy3ESaVlASqhzm/aiU9bp/ft2ydTp041Ncy+4nA4nGE0rVg3R7b288gjj8gff/whderUMS3TWkJh0fPUFml9zbWuWlvD0xKBGAAAIAm0xbN8+fKmlCHu6BJaA6tBWUsEdL62bGq9b1JFRUWZMgJtJbZcu3bNtBxbtETj9OnTsmDBAmnQoIEUK1Ys3na0Rvf69ete96PHr1xHojhz5oypVbaW+eq10lZi12HldNi6sLAwU/9s0d+1o6DWMWvruysto9C6bS3p+OKLL+TUqVOSVgjEAAAASaQtlto6rMOw3X333c75uXPnNp3Yvv32Wzl48KCpv9WQvHPnTrdQ6422mmq9rtbebtu2zYRJLSe4fPmycx3dp/ryyy9NBzgtJdDQretbIVjrnLXlWFuyPXVE0wCq29Xnbt++3bQ2d+vWTQoWLCjt2rXz0askpsRBS0i005++Ht99952MGTNG+vbta4K/0lpiLZfQ0Sv0HFxvfqIfLKyykM2bN0uBAgXMa5xWCMQAAADJCMQqbrmE1rdquYTWD1evXt08/vTTT03ntaSOzKCtoTq8Wf369U05gQ7LpkOjWXSZlmO8+OKL0qpVKzNqg/6urau//PKLWUdbr7UMoVy5cvLnn3963M+HH35owrzuR+t6z58/b47Tl2MVa4DVUSx+/PFH01quI21o4B89erRzHe1w+PDDD5uRJi5dumRGzXDtVKcBXQO8Bvfly5eb1u+0EuKwCjqQLPrm0d6T+unH6tUJAAASpiMH6KgIt912GzeLQJq/p5Ka12ghBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAA6Y4+/Qik9xKBGAAApBvrVr560wnAF6yxmlNza+ek30IFAAAglfRGEuHh4eY2xBpg0nJsWWT8luHLly+bG6BERkY6P2ylBIEYAACkG70jm94VTceN1TuYAamlYVhv85waBGIAAJCuQkNDpXTp0pRNINX0W4bUtAxbCMQAACDdaakEd6pDoPBr4c6aNWvMPbQjIiLMbfXq1KkjGzZsSPA5MTExMmvWLOnYsaMMHTo03vKRI0ear2PiTiVKlHCuM3PmzHjLW7ZsmSbnCAAAgMCWxd81H5MnT5Zy5crJ2bNnpXv37tK2bVsTer3p0qWLKaLevn27PPjgg/GWDx48WPr06eM2r2vXrqaA31Xt2rVlxYoVzsep6ZkIAACA4OXXQFytWjXn74UKFZLWrVubQHvz5k2vvU6//PJL06Lr+lxX+vWL61cwO3fulK+//lr+/PPPeL1cNZADAADA3gKihlhbfLdt2ybTp083JQ8JDcGiYTg5Bg0aJH379pXChQv74EgBAACQ0fh98L8ePXqYcoXq1atL+/btTYD1lfXr18vmzZtlwIAB8ZZt3LhRypcvb/a5Z8+eRLcVGxsr58+fd5sAAAAQ/PweiEePHi1btmyRKVOmyIQJE0xrrq8MHDhQevXqJTly5HCb36pVK1NK8eabb8qFCxdMxz49hoSMGzfOdPyzpqJFi/rsOAEAAOA/IY4Aupn4J598Ip07dzaDdRcvXjzBdbWGuEKFCmbECE+WLFkiHTp0kEOHDkmePHm8bkfrlXVbRYoUkeXLlyfYQqyTRVuINRSfO3dOcubMmaTzAwAAQPrRvKYNmYnlNb+3ELuqUaOGqSfev39/qraj2xg+fLg89thjCYZhpfXKut+9e/cmuF5YWJh5IV0nAAAABL+ACsRWLW9ircOJWb16tezatUs6deqUpPWjo6NTvU8AAAAEJ7+OMjFv3jxz+0Ztod23b5/069dPmjRpIiVLljTLGzZsaEaH0BtxWC5evCjXr1+XGzdumFs+6vjFug3XcYYXLlwouXPnlrp163rcr3ao07pibT1evHixrFq1ypRYAAAAwH782kKsHdq041upUqVMva+G4blz5zqXa+mE1gC7atasmQm7O3bsMIFaf9eRKlzpyBI1a9b0OkSb3g2vQYMGUrZsWZkzZ44J0NypDgAAwJ4CqlNdRizSBgAAgH8EZac6AAAAIL0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtubXQLxmzRqpXLmyRERESK5cuaROnTqyYcOGBJ8TExMjs2bNko4dO8rQoUPjLY+OjpaQkBC3KTIyMt56U6ZMkcKFC0vOnDmlW7ducuXKFZ+eGwAAAIKDXwOxBtXJkyfLvn37ZNOmTZIpUyZp27Ztgs/p0qWLzJs3T1atWiVHjx71ut6ZM2ec08GDB92WzZ49W8aNGyfz58+XrVu3ys6dO6VPnz4+Oy8AAAAEjxCHw+GQADF16lQZPHiwXLp0yYRjT/RwtdW3WrVqUqFCBZk5c2a8FuLbbrvNrOdNxYoVpVOnTtK/f3/zWENxrVq15PDhw5I/f/4kHev58+dNq/a5c+dMKzMAAAACS1LzWkDUEGt41VA6ffp0GTlypNcwrDQMp8aePXvk999/l/r16zvnVa1aVbJlyybLli1L1bYBAAAQfPweiHv06CFZs2aV6tWrS/v27WXQoEE+2e7tt98uTZs2ldWrV7vNP3TokPlZtGhRt5Ct9cRxSytcxcbGmk8ZrhMAAACCn98D8ejRo2XLli2mk9uECROkb9++qdqeBtu9e/fKnDlzTGnEQw89ZEoxLCdPnjQ/tUXYlT62lnmiNcfa5G5NroEaAAAAwSuLvw8gX758ZtKyhRw5ckjnzp1NB7fixYunaHva2ly6dGkzaV3w1atXZdSoUdKzZ0/JnDmzREVFmfV0vu7PoqNMWMs8GTJkiPTr18/5WFuICcUAAADBz+8txK5q1Khh6on379/vs21qKNaRJk6cOGEeW0H7yJEjznV0n/q4WLFiXrcTFhZmirFdJwAAAAS/gArE2uFNpbR12BMddSJ79uzO0SO05bhSpUqydu1a5zpasnHt2jVp0aKFz/YLAACA4ODXkgkdTzg0NNS0DOtYxFqS0KRJEylZsqRZ3rBhQ1MTrDfisFy8eFGuX78uN27cMCH27NmzZhvh4eFmubYu6/jEGnx15IpJkyZJ165d3UauGDBggLz00kum9ThPnjzSq1cv6dChgxQoUMAPrwIAAABsG4gvXLgg48ePN3ef0/pdHRVCO69ZNNxq8HXVrFkzWb9+vfl9x44dJlTrXeus8Yh1LGEdrUI7yGlLs4Zsa7xhy9NPPy3Hjx+Xli1bmtrhJ554Qt588810OWcAAAAEloC6MUcw4cYcAAAAgS2obswBAAAA+AuBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABga34NxGvWrJHKlStLRESE5MqVS+rUqSMbNmxI8DkxMTEya9Ys6dixowwdOjTe8lWrVkmDBg0kT548EhUVJR06dJBTp065rTNz5kwJCQlxm1q2bOnz8wMAAEDg82sgjoyMlMmTJ8u+fftk06ZNkilTJmnbtm2Cz+nSpYvMmzfPBN+jR4/GW75582Zp166d/PLLL7JixQrzWMNzXLVr15YzZ844p//9738+PTcAAAAEhyz+3Hm1atWcvxcqVEhat24tgwcPlps3b5pw7MmXX35pWnRdn+tqxIgRzt9vv/12GTRokHTt2lUuX74s4eHhzmVZsmQxgRwAAAD2FhA1xA6HQ7Zu3SrTp0+XkSNHeg3DSsNwcoSFhZmAHRsb64MjBQAAQEbj90Dco0cPyZo1q1SvXl3at29vWnR96bPPPjPbzp07t9v8jRs3Svny5c0+9+zZk+h2NFCfP3/ebQIAAEDw83sgHj16tGzZskWmTJkiEyZMkL59+/ps25988omsW7dOPvjgA7f5rVq1kp07d8qbb74pFy5cMB379BgSMm7cONPxz5qKFi3qs+MEAACA/4Q4tF4hQGiA7dy5sxw4cECKFy+e4LpaQ1yhQgUzYoQn2vFOW5+XLVsmdevW9bodLafQbRUpUkSWL1+eYAuxa9mFthBrKD537pzkzJkzSecHAACA9KN5TRsyE8trfm8hdlWjRg1TT7x///5Ubeerr76S7t27m1EmEgrDSuuVdb979+5NtBZZX0jXCQAAAMHPr6NMxGXV8ibWOpyQgwcPmmHXtBxCh1ZLiujo6FTtEwAAAMHLr4FYyxpCQ0NNC62ORdyvXz9p0qSJlCxZ0ixv2LChFC5c2NyIw3Lx4kW5fv263LhxQ65duyZnz54127CGVBs4cKBpGtcbbegyi7boWqNXaIe6HDlymJt3LF682IxpvGTJknQ/fwAAANg8EGuHtvHjx5u7z+ld5Zo2bWo6r1m0dEKDr6tmzZrJ+vXrze87duwwoVpvvGHVEv/0009y+PBhE3ZdaV1yiRIlzO96NzztwKc1wWXKlJGFCxdypzoAAACbCqhOdRmxSBsAAAD+EZSd6gAAAID0RiAGAACArRGIAQAAYGspCsTaCe2vv/5yPu7du7epz6hZs6bbfAAAACBDBuIXXnhBrl69an7XIdHeffddM2Ra/vz5zQ0xAAAAgAw97JqOBVygQAEzJNqYMWOkU6dOMmLECDly5IiULVvW90cJAAAABFIgrlq1qgwZMkSuXLli7gw3dOhQM//ff/81N7wAAAAAMnTJxEcffSSHDh2S3bt3y4IFC+S2224z85cvXy6NGjXy9TECAAAAaYYbc6QQN+YAAAAIbNyYAwAAAEiCFAXijRs3ytGjR52P33zzTalcubK0a9dOTpw4kZJNAgAAAMETiNu0aSP//POP+X3FihXSv39/09HuwIEDDLsGAACAjD/KxOnTp6VYsWLmdx1urXXr1jJjxgwTiO+66y5fHyMAAAAQWIFYxxp+5513zM05duzYYcKwunz5soSGhvr6GAEAAIA0k6JArGFYb8Zx8uRJeeutt6RSpUpm/uLFi+Wee+7x9TECAAAAwTHsmrYQZ86cWcLCwiSjY9g1AACAjJHXUtRCHPc2ziEhIRIRESHh4eGp3RwAAACQrlI8DvEHH3wgJUqUMKlbE7ferU7vYAcAAAAEkxS1EE+cOFHGjh0rzz//vBl/WKsutHPdSy+9ZJqm+/Xr5/sjBQAAAAKlhlhbg6dNmybNmzd3m7906VIThnX4tYyOGmIAAAAb37pZb8rhabzh6tWrO2/YAQAAAASDFAXiMmXKyIIFC+LNX7Rokdxxxx2+OC4AAAAgcGuIX3vtNWnVqpUZd1hriNVvv/0mW7Zskc8//9zXxwgAAAAEVgtxs2bNZOvWrVKyZEn56aefzKS/b9u2zYw8AQAAAGT4Ydf07nSzZs0ywVinTz/9VHLkyCEVK1ZM8jbWrFljWph1DGMteK5Tp45s2LAhwefExMSY/Xbs2FGGDh3qcZ1vvvlGKlSoINmzZ5dGjRpJdHR0vHWmTJkihQsXNgXW3bp1kytXriT5uAEAAJBxpDgQe5OcQSsiIyNl8uTJsm/fPtm0aZNkypRJ2rZtm+BzunTpIvPmzZNVq1bJ0aNH4y3fu3evtGzZUvr37y/79++X0qVLS9OmTeXGjRvOdWbPni3jxo2T+fPnmzC/c+dO6dOnTzLPFAAAABmBT2/dfPDgQbn99tvdwmdyTJ06VQYPHiyXLl0y4dgTPVy9M161atVMK/DMmTPdlr/44oumRfiLL74wj69duyYFCxaUjz/+2ARlpa3YnTp1MqFZaSiuVauWHD58WPLnz5+kY2XYNQAAABsPu+ZrGnI1lE6fPl1GjhzpNQwrDcMJ0ZEu6tev73wcGhpqwu7ChQvN4z179sjvv//utk7VqlUlW7ZssmzZMp+cDwAAADLgKBOJlTKoy5cvJ/sAevToYW4DffPmTRkzZowMGjRIUkpbg48fPy5FixZ1m6+PdRQMdejQIec815Ct9cTawu1NbGysmVw/cQAAAMBGgfjEiRNJWq9u3brJOoDRo0dL586d5YcffjCtw//++6/p8JYSp06dMq3N2trrSh+fPHnS/G79TGgdT7TmeNSoUSk6LgAAAGSAQLx27do0OYB8+fKZScsWdJQKDcfawa148eLJ3lbevHlNa+/Vq1fd5usIElFRUeZ366euo/vztI4nQ4YMMbeldm0hjtsSDQAAgOATEDXElho1apgWXh0dIiW0Xlg70B05csRtvpZJFCtWzPxuBW3XdXSf+thax5OwsDBTjO06AQAAIPgFVCDWDm8qJa3DljZt2ri1ZmtL8MaNG818pcOw6RjKruvoHfa0/rhFixapOn4AAADY5NbNvqLjCWurrrYM61jEWpLQpEkTc9c71bBhQ9PZTW/EYbl48aJcv37dDO2mIfbs2bNmG+Hh4WZ5z549pUqVKmasYX2+1iXfeuutbmF3wIAB8tJLL5nRJ/LkySO9evWSDh06SIECBfzwKgAAAMC2LcQXLlyQgQMHSqlSpUwg1TA8d+5c53ItnbBGhXC9bXTu3Lllx44dJlDr7zpShUVbgJcuXSpjx441wfrAgQPy9ddfS+bMmZ3rPP300yYU67jE1atXNwF62rRp6XTWAAAAyLA35rATbswBAAAQ2ILqxhwAAACAvxCIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC25tdAvGbNGqlcubJERERIrly5pE6dOrJhw4YEn7N9+3apUaOGZM+e3fzcsWOH2/JOnTpJSEhIvKlevXrOdUaOHBlveZ8+fdLsPAEAABC4/BqIIyMjZfLkybJv3z7ZtGmTZMqUSdq2bet1/dOnT0vjxo2lRYsW8vfff0vz5s2lSZMmcvbsWec67777rpw5c8Zt0uDsGohVu3bt3NYZN25cmp4rAAAAApNfA3G1atWkUaNGUqhQISlXrpy0bt3ahN6bN296XH/GjBlSsGBBefnll83PYcOGSf78+WXmzJnOdcLDw03QtiZtcT506JAMGDDAbVuhoaFu62mLMwAAAOwnIGqIHQ6HbN26VaZPn27KGbSl2JNFixbFa+nVxwsXLvS4vgbrwYMHy2uvvWbKMgAAAICAC8Q9evSQrFmzSvXq1aV9+/YyaNAgr+tqS2/RokXd5unjgwcPelx/1qxZcu3aNVNXHNf8+fOlSpUq0r17d4mJiUn0OGNjY+X8+fNuEwAAAIKf3wPx6NGjZcuWLTJlyhSZMGGC9O3b1+u6J0+elGzZsrnN08c6P66rV6/K8OHDZciQIfFanHv27Cnbtm2TV199Vf744w+pVKmSHDhwIMHj1Bpj7fhnTXGDOQAAAIKT3wNxvnz5pGrVqtK7d2/TwW7q1KleW3yjoqJM0HV15coVMz8u7Vyno0c89dRTHvdZtmxZ0ynv66+/lrCwMBPIE6LB+ty5c87p8OHDyT5XAAAABJ4sEkB0NAitJ96/f78UL1483nKdd+TIkXhlFMWKFXObd+nSJdOiqy3BWo6REO2Ep0O/7d27N8H1NDTrBAAAgIzF7y3Ervbs2WN+egrDqk2bNrJ27Vq3efpY57uaM2eOnDp1Sjp27Jik/UZHR3vdJwAAADI2vwbiefPmyeLFi02rrwbbfv36mXGFS5YsaZY3bNhQOnTo4FxfO8cdO3ZMxo8fb37qiBRaPxy305yOOqGtviVKlPC432+//daEb21d1lKIv/76Szp37pzGZwsAAIBA5NdAfOHCBRk4cKCUKlXKBF8Nw3PnznUu19IJDa2W3Llzy8qVK03g1bCrv69atcrMt2jJhXbSq1Wrltf9Ll++XO69914Tmjdu3CirV682o1wAAADAfkIcmiCRbDrsmo42oR3scubM6e/DAQAAQArzWkDVEAMAAADpjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsjUAMAAAAWyMQAwAAwNYIxAAAALA1AjEAAABsza+BeM2aNVK5cmWJiIiQXLlySZ06dWTDhg0JPmf79u1So0YNyZ49u/m5Y8cOt+Xr1q2TkJAQt6lKlSpu69y4cUOGDh0qefPmNZP+fvPmzTQ5RwAAAAQ2vwbiyMhImTx5suzbt082bdokmTJlkrZt23pd//Tp09K4cWNp0aKF/P3339K8eXNp0qSJnD171m29okWLypkzZ5zTDz/84LZ87NixsnjxYlm7dq2ZFi1aJOPHj0+z8wQAAEDg8msgrlatmjRq1EgKFSok5cqVk9atW5vQ6621dsaMGVKwYEF5+eWXzc9hw4ZJ/vz5ZebMmW7rabDWsG1NOXLkcC6LjY2VadOmmVBcqVIlM40bN07efPNNuXbtWpqfMwAAAAJLQNQQOxwO2bp1q0yfPl1GjhxpAq0n2pJbr149t3n6eOHChUnel5ZUnDx5UurXr++2jX///VfWr1/v9XkapM+fP+82AQAAIPj5PRD36NFDsmbNKtWrV5f27dvLoEGDvK576NAhUw7hSh8fPHjQbd7hw4flzjvvlEcffVR+/vnneNsIDw+XPHnyOOdpHbHWJMfdjittRdY6Z2uKexwAAAAITn4PxKNHj5YtW7bIlClTZMKECdK3b1+v62rLbrZs2dzm6WOdb7nnnntk9+7d8sEHH0ju3LlNx7vPP/88wW142k5cQ4YMkXPnzjknDd0AAAAIfln8fQD58uUzU9WqVU2tb+fOnaVPnz5SvHjxeOtGRUXJ1atX3eZduXLFzLdo6+8dd9xhpvvvv19OnDghw4cPl5YtW3rdhqftxBUWFmYmAAAAZCx+byF2pa25Wk+8f/9+j8s1JB85ciReCUSxYsW8brNWrVqyd+9et21cvnzZjD5h0dCsITmh7QAAACBjCqhAvGfPHvPTU+uwatOmjRkmzZU+1vneREdHu21PW421Jdh1O999952Zp8sAAABgL34tmZg3b56EhoaalmEdi7hfv35mXOGSJUua5Q0bNpTChQvLrFmzzONOnTqZzm06ZnDHjh3l/fffN3W/Ot/y66+/muHTihQpYoKuDsmmz7Ho/nr16mWGbtOOd//995/5vXfv3mYZAAAA7MWvgfjChQsm3MbExJgW2qZNm7qFVy2d0LvKWbST3MqVK6Vr164yYsQIcwe6VatWmfmWXbt2Sf/+/c2waBqsdXxhXT9uBznd93333SeZM2c2y3UeAAAA7CfEoUW7SDYN3Dr8mo44kTNnTn8fDgAAAFKY1wKqhhgAAABIbwRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICtEYgBAABgawRiAAAA2BqBGAAAALZGIAYAAICt+TUQr1mzRipXriwRERGSK1cuqVOnjmzYsCHB52zfvl1q1Kgh2bNnNz937Njhtnzu3LlSs2ZNyZkzpxQqVEh69+4tly9fdltn5MiREhIS4jb16dMnTc4RAAAAgc2vgTgyMlImT54s+/btk02bNkmmTJmkbdu2Xtc/ffq0NG7cWFq0aCF///23NG/eXJo0aSJnz551rrN582bp1auX/P777zJ79myZN2+eDBw4MN622rVrJ2fOnHFO48aNS7PzBAAAQODyayCuVq2aNGrUyLTklitXTlq3bm1C782bNz2uP2PGDClYsKC8/PLL5uewYcMkf/78MnPmTOc606ZNM2G3WLFi0rBhQ+nWrZssWrQo3rZCQ0NNILcmbXEGAACA/QREDbHD4ZCtW7fK9OnTTTmDthR7osG2Xr16bvP08cKFC71uOywsTK5cueLzYwYAAEDG4PdA3KNHD8maNatUr15d2rdvL4MGDfK67qFDh6Ro0aJu8/TxwYMHPa6vLc0alrWsIq758+dLlSpVpHv37hITE5PoccbGxsr58+fdJgAAAAQ/vwfi0aNHy5YtW2TKlCkyYcIE6du3r9d1T548KdmyZXObp491vifa2nz8+HF544033Ob37NlTtm3bJq+++qr88ccfUqlSJTlw4ECCx6k1xtrxz5riBnMAAAAEJ78H4nz58knVqlXNaBDawW7q1KleW3yjoqLk6tWrbvO0HELnx6Xh+sMPP5TvvvtOihQpEm+fZcuWNZ3yvv76a1NWoYE8IUOGDJFz5845p8OHD6fofAEAABBYskgA0WHUtJ54//79Urx48XjLdd6RI0filVFoBzpXWousrcLr16+XO++8M8F9hoeHm6Hf9u7dm+B6Gpp1AgAAQMbi9xZiV3v27DE/PYVh1aZNG1m7dq3bPH2s8y0///yzvPjii2Y84sTCsCU6OtrrPgEAAJCx+TUQ6xjBixcvNq2+Gmz79etnOsCVLFnSLNdh0zp06OBcv1OnTnLs2DEZP368+ak1wlo/rPNd64N1ODctw9Dxia3J1bfffmvCt7YuaynEX3/9JZ07d07HMwcAAECg8GvJxIULF0y41VEetA64adOmbjfI0NKJGzduOB/nzp1bVq5cKV27dpURI0aYUSJWrVpl5lu0g561ristxbAsX75cZs2aZX7XDnWrV682o1wAAADAfkIcrkkRSabDruloE9rBTm8TDQAAgODMawFVQwwAAACkNwIxAAAAbI1ADAAAAFsjEAMAAMDWCMQAAACwNQIxAAAAbI1ADAAAAFsjEAMAAMDWCMQAAACwNQIxAAAAbI1ADAAAAFsjEAMAAMDWCMQAAACwNQIxAAAAbI1ADAAAAFsjEAMAAMDWCMQAAACwNQIxAAAAbI1ADAAAAFsjEAMAAMDWCMQAAACwNQIxAAAAbC2Lvw8gWDkcDvPz/Pnz/j4UAAAAeGDlNCu3eUMgTqELFy6Yn0WLFvX3oQAAACCR3JYrVy6vy0MciUVmeHTz5k05evSo5MiRQ0JCQvx9OBniE5x+uDh8+LDkzJnT34eDFOAaBj+uYfDjGgY3rp/vaczVMFyoUCHJlMl7pTAtxCmkL2qRIkX8fRgZjv4PgP8JBDeuYfDjGgY/rmFw4/r5VkItwxY61QEAAMDWCMQAAACwNQIxAkJYWJiMGDHC/ERw4hoGP65h8OMaBjeun//QqQ4AAAC2RgsxAAAAbI1ADAAAAFsjEAMAAMDWCMRIN998841UqFBBsmfPLo0aNZLo6OhEn7N9+3apUaOGeY7+3LFjh9d1f/nlF8mSJYvMnDnTx0eOtLyGc+fOlZo1a5oxN3Xg9N69e8vly5fT8CzsI7nXKyl/b3q9SpYsKREREdKmTRs5depUGp4BfH0N+XvLGH+HFv7d8x0CMdLF3r17pWXLltK/f3/Zv3+/lC5dWpo2bSo3btzw+pzTp09L48aNpUWLFvL3339L8+bNpUmTJnL27Nl4616/fl26dOli7iCI4LqGmzdvll69esnvv/8us2fPlnnz5snAgQPT6awyruRer6Rcq/Xr10vXrl1l6tSpsnv3brOtJ598Mh3Pyl7S4hry9xb819DCv3s+pqNMAGmtZ8+ejmbNmjkfx8bGOvLkyeNYunSp1+dMmjTJUbFiRbd5FSpUcEyZMiXeuuPHj3eUL1/eUbNmTceMGTN8fPRIj2toGTZsmKNAgQI+Omr7Su71Ssq10u3pdi3Hjh1zZM6c2bF9+/Y0OQe7S4trGBd/b8F7Dfl3z7doIUa6WLRokdSvX9/5ODQ0VGrVqiULFy5M8Dn16tVzm6eP4z7nwIED8uqrr8rHH39stovgu4audPzNK1eu+Oio7Su51yuxa6Vfq3/11Vdu2yxQoICULVs2weuJwLmGnvD3FpzXkH/3fI9AjDR37do1OX78uBQtWtRtvj4+ePCg1+cdOnQoSc95/vnnpXPnzqbWCsF5DS361Z/+j1+/IkT6Xq/ErlVMTIy5Psl9DyBwrmFc/L0F7zXk3z3fy5IG2wTcaKcbvf9LtmzZ3Obr45MnT3p9ni5L7Dlz5swxNVpLlixJgyNHelxDVyNHjjT/gHz55Zc+OnJ7Ssn1SuxaWT+T+x5A4FzDuPh7C85ryL97aYMWYqSK/g81JCTE6zRs2DDJmzev+f3q1atuz9Wv6aKiorxuW5cl9Bz9n02/fv3kgw8+MD3eEXzX0NWECRPkww8/lO+++06KFCniwzO0n5Rcr8SulfUzue8BBM41dMXfW3BeQ/7dSzsEYqQ6TOknYG/Ta6+9ZuqbChYsKEeOHIn31VCxYsW8brt48eIJPmfFihVy4sQJeeihh8ywMzppL/jnnntOGjZsmEZnnPH48xpapk+fLm+88YasW7dOypUr5+MztJ+UXK/ErlXhwoUlc+bMyX4PIHCuoYW/t+C9hvy7l3YIxEgXOl7p2rVrnY/1E/DGjRvN/KQ+R+lj6zmPPPKI7Ny504zRaE06rubo0aPlo48+SsOzsae0uIbq559/lhdffNGMj3rnnXem0dHbT3KvV2LXSsdEffjhh93W+eeff+TPP/9M8D2AwLmGir+34L6G/LuXhnw8agXg0d69ex3h4eGOWbNmOWJiYhxdunRxlClTxnH9+nXnOg0aNHC0b9/e+fj06dOOqKgox+uvv+74559/HCNGjDCPdb43xYsXZ/iZILuG99xzjxk26MyZM24T0vZ6peRarV+/3hEREeH4+uuvHdHR0WY4qUaNGvnl/OwgLa4hf2/Bfw3j4t893yAQI92sWrXK/I8gW7Zs5h/RAwcOxPujvv/++93mbd261XH33Xc7wsLCHDVq1HBs27YtwX3wP4bgu4b6udzThLS9Xin9e5s9e7Z5rv4j36ZNG8fJkyfT5VzsytfXkL+3jPF36Ip/93wjRP+Tli3QAAAAQCCjhhgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAAAC2RiAGAACArRGIAQAAYGsEYgAAANgagRgAgkC9evUkJCTEbSpTpkyqt7tu3Tqzrejo6AT33alTp1TvCwACVRZ/HwAAIGlatGghn376qfNx5syZ02W/K1askEyZ/n/7yerVqyUmJkaeeeaZdNk/AKQ1AjEABImsWbNKZGRkuu/3lltucXs8d+5c06KcmkAcGxsrYWFhPjg6AEg9SiYAIIj98ssvHkseKlWqJO+99575vW/fvlK6dGnJnj273HnnnfLNN98kax+uJRMjR440rdTr1683+3UtpXjjjTekcOHCkidPHuncubNcuXLFuUzX0+3oMd16660yadKkVJ45APgOgRgAgli1atWkZMmS8tlnnznn7dixQ/bs2SOPP/64eVyoUCFZsmSJ7N+/3wTlHj16pHh/gwcPlnbt2knt2rXlzJkz8u677zpbjTUQ6342btwoP/30k4wZM8btub///rsJ4z/++GOqjgEAfI1ADABBYvny5aZkwpp2795t5mvwdQ3Es2fPlqZNm5qWWjVgwACpWLGiCcY6/++//07xMWTLlk1CQ0MlS5Ys5hjCw8PN/Ndff92E3Bo1apjOfs8++6zMnz8/XunFvHnzpFSpUpI7d+4UHwMA+Bo1xAAQJBo1auRskVVanmAF4rFjx8qff/5pSiO0tfadd95xG0li2rRpsmvXLtMZ7ubNmz49ruvXr5twri3CEyZMMPOuXbsWbz8lSpSgbhhAQCIQA0CQ0NZYDZVxaRlE2bJlTSvxvffeazqsPfzww2bZmjVrpHHjxqb1dsiQIab2V1uMfUmD740bN2To0KHy1FNP+XTbAJAeCMQAkAFYZRP79u2Ttm3bOltitaa3fPny8vbbb5vH2kqcWjrcm7YKW7SEokqVKqZu+OWXX0719gEgvVFDDABB4r///pOzZ8+6TVZZwhNPPGFKJhYsWCDt27d3Pqdo0aJy+PBh2bZtm+nM9tZbb5n5Gl5TSmuAtePe1q1bzTGoUaNGmfGKX3nlFVOjrB34Pv7441SfMwCkBwIxAARRpzrtjOY6WR3kdDi1ypUrS7FixcwIEJaePXtKnTp1zKRhdebMmabjW7NmzdxaeZOje/fuZh9169aViRMnmnnNmzeXpUuXmlCs5Ru1atUyjwEgGIQ4HA6Hvw8CAAAA8BdaiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAtkYgBgAAgK0RiAEAAGBrBGIAAADYGoEYAAAAYmf/B6m3K5DC3ESGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\", \n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8 - 3064.0 ms/stepp"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions = language_model(X_test[:256], batch_size=batch_size, verbose=True)\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions.data, axis=1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:256], predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tema vinotta me, telle do Plenda amente: amarcome brac'io vennel nella,\n",
      "due suoha\n",
      "dio rei li nontate tanto egon suote\n",
      "per sofferto d'in quanto mil vidi mal cammir alla,\n",
      "ch'uommi volta\n",
      "grazia, 'om li spestul un li erra mia voltaglio avera\n",
      "maestro per forte in questo del no dolcipi con ffeondo si inse,\n",
      "pregirtu petto affetto\n",
      "col gir "
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
