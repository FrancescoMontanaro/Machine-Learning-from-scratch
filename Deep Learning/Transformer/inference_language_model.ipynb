{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor\n",
    "from src.architectures.transformer import Tokenizer, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants & Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the tokenizer and model files\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model from the checkpoint...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Check if the model is already trained\n",
    "if os.path.exists(model_path):\n",
    "    # Printa status\n",
    "    print(\"Loading the model from the checkpoint...\")\n",
    "    \n",
    "    # Load the model\n",
    "    language_model = Transformer.load(model_path)\n",
    "    \n",
    "    # Print status\n",
    "    print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcia loco\n",
      "ov'era poi forse dava minor che dentro:\n",
      "questo, per lo sol dicento di quel dell'apppo,\n",
      "non far voler restato con l'attende,\n",
      "e false le man del dimandato Dio mi diedi.\n",
      "Qual con merito in quell'agutai per la lava\n",
      "per brugava dir per lo suo petto e per tanto quadrando sapor fa nota;\n",
      "e per cerchi scondeva e qual ora.\n",
      "Ma voltesi fidar cabro e da\n",
      "Li attriti e dell'uomo statesti umana;\n",
      "e questa da quelli spirti, stava,\n",
      "e con l'altra mentemensa odere ed che digiuna\n",
      "qual nel primo ti precisa era,\n",
      "Ca"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.generate(context, max_new_tokens=300, stream=True): # type: ignore\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
