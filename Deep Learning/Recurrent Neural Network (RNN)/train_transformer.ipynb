{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36912af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import the module from the custom library\n",
    "from src.architectures.transformer import EncoderDecoderTransformer\n",
    "from src.architectures.auto_regressive import AutoRegressive\n",
    "from src.core.utils import data_analysis, data_processing, context_manager\n",
    "from src import Tensor, layers, loss_functions, optimizers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370a12a",
   "metadata": {},
   "source": [
    "### Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd8f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to where the model will be saved\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'stock_prediction_transformer')\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'SPX.csv')\n",
    "\n",
    "# Define the feature and target columns\n",
    "feature_columns = ['Open', 'High', 'Low', 'Close']\n",
    "close_price_idx = feature_columns.index('Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5aea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the model\n",
    "normalization: Literal['minmax', 'standard'] = 'standard'\n",
    "train_test_split_pct = 0.1\n",
    "train_valid_split_pct = 0.1\n",
    "n_attention_heads = 4\n",
    "n_decoder_blocks = 4\n",
    "learning_rate = 5e-4\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_embed = 64\n",
    "seq_len = 128\n",
    "seed = 1234\n",
    "\n",
    "# Volatility prediction settings\n",
    "predict_volatility = True\n",
    "volatility_window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f250322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abdf8a",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4516c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Load data from a CSV file with proper date parsing.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - data: list[dict], list of dictionaries containing the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to hold the data\n",
    "    data = []\n",
    "    \n",
    "    # Open the CSV file and read its contents\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Use DictReader to read the CSV file into a list of dictionaries\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Ensure the 'Date' field is in the correct format\n",
    "            try:\n",
    "                # Parse the date and convert it to a datetime object\n",
    "                datetime.strptime(row['Date'], '%Y-%m-%d')\n",
    "                \n",
    "                # Add the row to the data list\n",
    "                data.append(row)\n",
    "                \n",
    "            except ValueError:\n",
    "                # If the date is invalid, skip this row\n",
    "                print(f\"Skipping row with invalid date: {row['Date']}\")\n",
    "                continue\n",
    "    \n",
    "    # Sort the data by date\n",
    "    data.sort(key=lambda x: x['Date'])\n",
    "    \n",
    "    # return the loaded and sorted data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9475ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23323 data points\n",
      "Date range: 1927-12-30 to 2020-11-04\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = load_data(dataset_path)\n",
    "\n",
    "# Print the number of data points and the date range\n",
    "print(f\"Loaded {len(data)} data points\")\n",
    "print(f\"Date range: {data[0]['Date']} to {data[-1]['Date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9944da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price data shape: (23323, 4)\n",
      "Timestamps shape: (23323,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the feature and timestamp data\n",
    "features = np.array([[np.float32(data[j][k]) for k in feature_columns] for j in range(len(data))])\n",
    "timestamps = np.array([datetime.strptime(data[j]['Date'], '%Y-%m-%d').timestamp() for j in range(len(data))], dtype=np.int32)\n",
    "\n",
    "# Print the shapes of the features and dates arrays\n",
    "print(f\"Price data shape: {features.shape}\")\n",
    "print(f\"Timestamps shape: {timestamps.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8eaf0",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cd0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_returns(prices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate log returns: ln(P_t / P_{t-1})\n",
    "    \n",
    "    Parameters:\n",
    "    - prices: np.ndarray, absolute prices with shape (T, F)\n",
    "    \n",
    "    Returns:\n",
    "    - log_returns: np.ndarray, log returns with shape (T-1, F)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute log returns using the formula ln(P_t / P_{t-1})\n",
    "    return np.log(prices[1:] / prices[:-1])\n",
    "\n",
    "\n",
    "def compute_realized_volatility(log_returns: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate realized volatility using rolling window of squared returns.\n",
    "    \n",
    "    Parameters:\n",
    "    - log_returns: np.ndarray, log returns with shape (T, F)\n",
    "    - window: int, rolling window size\n",
    "    \n",
    "    Returns:\n",
    "    - volatility: np.ndarray, realized volatility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute squared log returns\n",
    "    squared_returns = log_returns ** 2\n",
    "    \n",
    "    # Initialize an empty list to hold the volatility values\n",
    "    volatility = []\n",
    "    \n",
    "    # Iterate over the log returns with a rolling window\n",
    "    for i in range(window, len(squared_returns)):\n",
    "        # Calculate the volatility as the square root of the mean of squared returns\n",
    "        vol = np.sqrt(np.mean(squared_returns[i-window:i], axis=0))\n",
    "        \n",
    "        # Append the calculated volatility to the list\n",
    "        volatility.append(vol)\n",
    "    \n",
    "    # Convert the list to a numpy array and return\n",
    "    return np.array(volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8f091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log returns shape: (23322, 4)\n",
      "Log returns stats - Mean: [0.00022563 0.00022662 0.00022561 0.00022609]\n",
      "Log returns stats - Std: [0.01179839 0.01105997 0.01168979 0.01202147]\n",
      "Realized volatility shape: (23317, 4)\n"
     ]
    }
   ],
   "source": [
    "# Compute log returns\n",
    "log_returns = compute_log_returns(features)\n",
    "timestamps_returns = timestamps[1:]\n",
    "\n",
    "# Print the shape and statistics of the log returns\n",
    "print(f\"Log returns shape: {log_returns.shape}\")\n",
    "print(f\"Log returns stats - Mean: {np.mean(log_returns, axis=0)}\")\n",
    "print(f\"Log returns stats - Std: {np.std(log_returns, axis=0)}\")\n",
    "\n",
    "# Compute realized volatility if required\n",
    "if predict_volatility:\n",
    "    # Compute realized volatility using a rolling window\n",
    "    realized_volatility = compute_realized_volatility(log_returns, volatility_window)\n",
    "    \n",
    "    # Adjust timestamp for the volatility data\n",
    "    timestamps_volatility = timestamps_returns[volatility_window:]\n",
    "    \n",
    "    # Print the shape and statistics of the realized volatility\n",
    "    print(f\"Realized volatility shape: {realized_volatility.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a013",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe965bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target data shape: (23317, 4)\n",
      "Input data shape: (23317, 4)\n",
      "Input timestamps shape: (23317,)\n"
     ]
    }
   ],
   "source": [
    "# Set the target data based on whether we are predicting volatility or log returns\n",
    "if predict_volatility:\n",
    "    # Use realized volatility as target data\n",
    "    target_data = realized_volatility\n",
    "    input_data = log_returns[volatility_window:] \n",
    "    input_timestamps = timestamps_volatility\n",
    "    \n",
    "else:\n",
    "    # Use log returns as target data\n",
    "    target_data = log_returns\n",
    "    input_data = log_returns\n",
    "    input_timestamps = timestamps_returns\n",
    "\n",
    "# Perform the temporal split\n",
    "print(f\"Target data shape: {target_data.shape}\")\n",
    "print(f\"Input data shape: {input_data.shape}\")\n",
    "print(f\"Input timestamps shape: {input_timestamps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270408fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, target_data: np.ndarray, timestamps: np.ndarray, seq_length: int) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - target_data: np.ndarray, target values (aligned with input_data)\n",
    "    - timestamps: np.ndarray, timestamps corresponding to input_data\n",
    "    - seq_length: int, length of input sequences\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor, Tensor]: input sequences, target values, and timestamps as Tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y, ts = [], [], []\n",
    "    \n",
    "    # Iterate over the input data to create sequences\n",
    "    for i in range(seq_length, len(input_data)):\n",
    "        # Append the sequence of input and the corresponding target\n",
    "        X.append(input_data[i-seq_length:i])\n",
    "        y.append(target_data[i])\n",
    "        ts.append(timestamps[i])\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return (\n",
    "        Tensor(np.array(X, dtype=np.float32)),\n",
    "        Tensor(np.array(y, dtype=np.float32)),\n",
    "        Tensor(np.array(ts, dtype=np.int32))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0677c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (23189, 128, 4)\n",
      "Targets shape: (23189, 4)\n",
      "Timestamps shape: (23189,)\n"
     ]
    }
   ],
   "source": [
    "# Build sequences\n",
    "features, targets, sequence_timestamps = build_sequences(input_data, target_data, input_timestamps, seq_len)\n",
    "\n",
    "# Print the shapes of the features and targets\n",
    "print(f\"Features shape: {features.shape()}\")\n",
    "print(f\"Targets shape: {targets.shape()}\")\n",
    "print(f\"Timestamps shape: {sequence_timestamps.shape()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a6229",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57cc4b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (18784, 128, 4) (18784, 4)\n",
      "Validation set: (2087, 128, 4) (2087, 4)\n",
      "Testing set: (2318, 128, 4) (2318, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "(X_train, X_test, y_train, y_test), train_test_shuffle_indices = data_processing.split_data((features, targets), train_test_split_pct, shuffle=True)\n",
    "(X_train, X_valid, y_train, y_valid), train_valid_shuffle_indices = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)\n",
    "\n",
    "# Ensure the shuffle indices are numpy arrays\n",
    "assert isinstance(train_test_shuffle_indices, np.ndarray), \"train_test_shuffle_indices should be a numpy array\"\n",
    "assert isinstance(train_valid_shuffle_indices, np.ndarray), \"train_valid_shuffle_indices should be a numpy array\"\n",
    "\n",
    "# Extract the timestamps for each set\n",
    "train_timestamps, test_timestamps = data_processing.split_data(sequence_timestamps[train_test_shuffle_indices], train_test_split_pct, shuffle=False)[0]\n",
    "train_timestamps, valid_timestamps = data_processing.split_data(train_timestamps[train_valid_shuffle_indices], train_valid_split_pct, shuffle=False)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape(), y_train.shape())\n",
    "print('Validation set:', X_valid.shape(), y_valid.shape())\n",
    "print('Testing set:', X_test.shape(), y_test.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38547b2c",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8445526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization statistics (from training data only):\n",
      "Min: [-0.2280193  -0.14060071 -0.22485887 -0.22899728]\n",
      "Max: [0.1536613 0.1536613 0.1536613 0.1536613]\n",
      "Mean: [0.00022669 0.00022696 0.00022622 0.00022663]\n",
      "Std: [0.01176694 0.01102685 0.01165611 0.01198834]\n"
     ]
    }
   ],
   "source": [
    "# Compute normalization statistics from training data only\n",
    "mean, std, min, max = data_processing.compute_stats(X=X_train, axis=(0, 1))\n",
    "\n",
    "# Print the normalization statistics\n",
    "print('Normalization statistics (from training data only):')\n",
    "print('Min:', min.to_numpy())\n",
    "print('Max:', max.to_numpy())\n",
    "print('Mean:', mean.to_numpy())\n",
    "print('Std:', std.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e910a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalization functions based on the normalization method\n",
    "def normalization_fn(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Normalize input data based on the specified normalization method.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: Tensor, input data to normalize\n",
    "    \n",
    "    Returns:\n",
    "    - Tensor, normalized data\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalization == 'minmax':\n",
    "        # Normalize using Min-Max normalization\n",
    "        return data_processing.min_max_normalize(x, min, max)\n",
    "    else:\n",
    "        # Normalize using Z-score normalization\n",
    "        return data_processing.z_score_normalize(x, mean, std)\n",
    "\n",
    "\n",
    "# Define denormalization functions based on the normalization method\n",
    "def denormalization_fn(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Denormalize input data based on the specified normalization method.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: Tensor, normalized data to denormalize\n",
    "    \n",
    "    Returns:\n",
    "    - Tensor, denormalized data\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalization == 'minmax':\n",
    "        # Denormalize using Min-Max normalization\n",
    "        return data_processing.min_max_denormalize(x, min, max)\n",
    "    else:\n",
    "        # Denormalize using Z-score normalization\n",
    "        return data_processing.z_score_denormalize(x, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca894cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training, validation, and test sets using training statistics\n",
    "X_train_norm = normalization_fn(X_train)\n",
    "X_valid_norm = normalization_fn(X_valid)\n",
    "X_test_norm = normalization_fn(X_test)\n",
    "\n",
    "# Normalize the target variable using the computed statistics\n",
    "y_train_norm = normalization_fn(y_train)\n",
    "y_valid_norm = normalization_fn(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151906f",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a29015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = AutoRegressive(\n",
    "    name = \"Stock prediction model\",\n",
    "    sequence_length = seq_len,\n",
    "    modules = [\n",
    "        EncoderDecoderTransformer(\n",
    "            encoder_input_dim = len(feature_columns),\n",
    "            encoder_sequence_length = seq_len,\n",
    "            n_encoder_blocks = n_decoder_blocks,\n",
    "            decoder_sequence_length = seq_len,\n",
    "            decoder_input_dim = len(feature_columns),\n",
    "            n_embed = n_embed,\n",
    "            n_attention_heads = n_attention_heads,\n",
    "            n_decoder_blocks = n_decoder_blocks,\n",
    "            dropout = 0.3,\n",
    "            data_type = 'continuous'\n",
    "        ),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_units=32),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_units=y_train.shape()[-1])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the optimizer with lower learning rate\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.MeanSquareError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8964da2",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d11e559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    model(x=X_train_norm[:batch_size], encoder_input=X_train_norm[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "029a96c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock prediction model (AutoRegressive) [output_shape=(32, 4), params=482472]\n",
      "└── stock_prediction_model.modules (ModuleList) [output_shape=(32, 4), params=482472]\n",
      "    ├── module_list.0 (EncoderDecoderTransformer) [output_shape=(32, 4), params=482180]\n",
      "    │   └── encoder_decoder_transformer.modules (ModuleList) [output_shape=(32, 4), params=482180]\n",
      "    │       └── module_list.0 (EncoderDecoder) [output_shape=(32, 4), params=482180]\n",
      "    │           ├── encoder_decoder.encoder (Encoder) [output_shape=(32, 128, 64), params=207808]\n",
      "    │           │   ├── encoder.input_proj (Dense) [output_shape=(32, 128, 64), params=320]\n",
      "    │           │   ├── encoder.positional_embedding (Embedding) [output_shape=(128, 64), params=8192]\n",
      "    │           │   ├── encoder.encoder_blocks (ModuleList) [output_shape=?, params=199168]\n",
      "    │           │   │   ├── module_list.0 (Block) [output_shape=(32, 128, 64), params=49792]\n",
      "    │           │   │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │           │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │           │   │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   └── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │           │   │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │       └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │           │   │   ├── module_list.1 (Block) [output_shape=(32, 128, 64), params=49792]\n",
      "    │           │   │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │           │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │           │   │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   └── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │           │   │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │       └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │           │   │   ├── module_list.2 (Block) [output_shape=(32, 128, 64), params=49792]\n",
      "    │           │   │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │           │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │           │   │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │   │   └── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │           │   │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │   │       └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │           │   │   └── module_list.3 (Block) [output_shape=(32, 128, 64), params=49792]\n",
      "    │           │   │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │       ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │           │   │       │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │       │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │           │   │       │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           │   │       └── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │           │   │           ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │           │   │           │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │           │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │           │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │           │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │           │   │           │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │           │   │           │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │           │   │           ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │           │   │           └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │           │   └── encoder.layer_norm (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │           └── encoder_decoder.decoder (Decoder) [output_shape=(32, 1, 4), params=274372]\n",
      "    │               ├── decoder.input_proj (Dense) [output_shape=(32, 128, 64), params=320]\n",
      "    │               ├── decoder.positional_embedding (Embedding) [output_shape=(128, 64), params=8192]\n",
      "    │               ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=265472]\n",
      "    │               │   ├── module_list.0 (Block) [output_shape=(32, 128, 64), params=66368]\n",
      "    │               │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.layer_norm_cross (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │               │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │               │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   │   └── module_list.0.cross_attention_heads (CrossMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │       ├── cross_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │       │   ├── module_list.0 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.1 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.2 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   └── module_list.3 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │       ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       ├── cross_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │       └── module_list.0.cross_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   ├── module_list.1 (Block) [output_shape=(32, 128, 64), params=66368]\n",
      "    │               │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.layer_norm_cross (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │               │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │               │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   │   └── module_list.1.cross_attention_heads (CrossMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │       ├── cross_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │       │   ├── module_list.0 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.1 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.2 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   └── module_list.3 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │       ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       ├── cross_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │       └── module_list.1.cross_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   ├── module_list.2 (Block) [output_shape=(32, 128, 64), params=66368]\n",
      "    │               │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.layer_norm_cross (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │               │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │               │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │   │   ├── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │   │   └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   │   └── module_list.2.cross_attention_heads (CrossMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │   │       ├── cross_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │   │       │   ├── module_list.0 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.1 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   ├── module_list.2 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       │   └── module_list.3 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │   │       │       ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │   │       │       └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │   │       ├── cross_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │   │       └── module_list.2.cross_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │   └── module_list.3 (Block) [output_shape=(32, 128, 64), params=66368]\n",
      "    │               │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │       ├── block.layer_norm_cross (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │       ├── block.mlp (MLP) [output_shape=(32, 128, 64), params=33088]\n",
      "    │               │       │   ├── mlp.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │       │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 128, 256), params=16640]\n",
      "    │               │       │   └── block.mlp.output_dense (Dense) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               │       ├── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │       │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │       │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │       │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │       │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │       │   │   └── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │       │   │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │       │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │       │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │       │   └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               │       └── module_list.3.cross_attention_heads (CrossMultiHeadAttention) [output_shape=(32, 128, 64), params=16448]\n",
      "    │               │           ├── cross_multi_head_attention.heads (ModuleList) [output_shape=?, params=12288]\n",
      "    │               │           │   ├── module_list.0 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │           │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │           │   ├── module_list.1 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │           │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │           │   ├── module_list.2 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │           │   │   ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │   │   └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │           │   └── module_list.3 (CrossSingleHeadAttention) [output_shape=(32, 128, 16), params=3072]\n",
      "    │               │           │       ├── cross_single_head_attention.key (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │       ├── cross_single_head_attention.query (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │       ├── cross_single_head_attention.value (Dense) [output_shape=(32, 128, 16), params=1024]\n",
      "    │               │           │       └── cross_single_head_attention.dropout (Dropout) [output_shape=(32, 128, 128), params=0]\n",
      "    │               │           ├── cross_multi_head_attention.dropout (Dropout) [output_shape=(32, 128, 64), params=0]\n",
      "    │               │           └── module_list.3.cross_attention_heads.output_linear (Dense) [output_shape=(32, 128, 64), params=4160]\n",
      "    │               ├── decoder.layer_norm (LayerNormalization) [output_shape=(32, 128, 64), params=128]\n",
      "    │               └── decoder.output_layer (Dense) [output_shape=(32, 128, 4), params=260]\n",
      "    ├── module_list.1 (Dropout) [output_shape=(32, 4), params=0]\n",
      "    ├── module_list.2 (Dense) [output_shape=(32, 32), params=160]\n",
      "    ├── module_list.3 (Dropout) [output_shape=(32, 32), params=0]\n",
      "    └── module_list.4 (Dense) [output_shape=(32, 4), params=132]\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ec304",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf48ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training with early stopping\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_valid_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_valid_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_absolute_error\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train_norm\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/sequential/sequential.py:89\u001b[0m, in \u001b[0;36mSequential.fit\u001b[0;34m(self, X_train, y_train, X_valid, y_valid, optimizer, loss_fn, batch_size, gradient_accumulation_steps, epochs, metrics, callbacks, shuffle_between_epochs, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Compute the output of the model\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Set the parameters of the optimizer\u001b[39;00m\n\u001b[1;32m     92\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mset_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:91\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mMethod to call the forward method of the module\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m- Tensor: Output of the module after the forward pass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Call the forward method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/sequential/sequential.py:268\u001b[0m, in \u001b[0;36mSequential._forward\u001b[0;34m(self, x, batch_size, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m x[step \u001b[38;5;241m*\u001b[39m batch_size:(step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Forward pass: Compute the output of the model\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Append the output of the batch\u001b[39;00m\n\u001b[1;32m    271\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(batch_out)\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/modules_list.py:148\u001b[0m, in \u001b[0;36mModuleList._forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Iterate over the modules\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# Perform the forward pass\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Return the output tensor\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/sequential/sequential.py:268\u001b[0m, in \u001b[0;36mSequential._forward\u001b[0;34m(self, x, batch_size, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m x[step \u001b[38;5;241m*\u001b[39m batch_size:(step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Forward pass: Compute the output of the model\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Append the output of the batch\u001b[39;00m\n\u001b[1;32m    271\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(batch_out)\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/modules_list.py:148\u001b[0m, in \u001b[0;36mModuleList._forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Iterate over the modules\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# Perform the forward pass\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Return the output tensor\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/encoder_decoder.py:113\u001b[0m, in \u001b[0;36mEncoderDecoder._forward\u001b[0;34m(self, x, encoder_input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mFull forward pass through encoder and decoder.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m- Tensor: Output from the decoder, which is the final output of the model\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Compute the encoder output\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, S_enc, E) -> (B, S_enc, E)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Compute the decoder output\u001b[39;00m\n\u001b[1;32m    116\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, encoder_output) \u001b[38;5;66;03m# (B, S_dec, E) -> (B, S_dec, O)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:91\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mMethod to call the forward method of the module\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m- Tensor: Output of the module after the forward pass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Call the forward method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/encoder.py:108\u001b[0m, in \u001b[0;36mEncoder._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Apply the encoder blocks\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_blocks:\n\u001b[0;32m--> 108\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, S, E) -> (B, S, E)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Apply layer normalization and return the encoded representations\u001b[39;00m\n\u001b[1;32m    111\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(embeddings) \u001b[38;5;66;03m# (B, S, E) -> (B, S, E)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:91\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mMethod to call the forward method of the module\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m- Tensor: Output of the module after the forward pass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Call the forward method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/block.py:82\u001b[0m, in \u001b[0;36mBlock._forward\u001b[0;34m(self, x, encoder_output)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mForward pass of the transformer block.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m- ValueError: If cross-attention is used but encoder_output is not provided.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Dimensions are:\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# - B: batch size\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# - S: sequence length\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# - E: embedding size (embedding dimension of the original data)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Apply the multi-attention mechanism with skip connections\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m out \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, S, E) + (B, S, E) -> (B, S, E)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Check if cross-attention has to be applied\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cross_attention:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Ensure that encoder_output is provided\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:91\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mMethod to call the forward method of the module\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m- Tensor: Output of the module after the forward pass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Call the forward method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/self_attention.py:173\u001b[0m, in \u001b[0;36mSelfMultiHeadAttention._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mForward pass of the MultiHeadAttention module\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m- Tensor: The output tensor\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Dimensions are:\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# - B: batch size\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# - S: sequence length\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Apply each head to the embeddings\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m out \u001b[38;5;241m=\u001b[39m concat(\u001b[43m[\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, S, E) -> (B, S, H * n_heads)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Apply the output linear layer to project the embeddings back to the original size\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear(out))\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/self_attention.py:173\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mForward pass of the MultiHeadAttention module\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m- Tensor: The output tensor\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Dimensions are:\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# - B: batch size\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# - S: sequence length\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Apply each head to the embeddings\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m out \u001b[38;5;241m=\u001b[39m concat([\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, S, E) -> (B, S, H * n_heads)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Apply the output linear layer to project the embeddings back to the original size\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear(out))\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:91\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mMethod to call the forward method of the module\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m- Tensor: Output of the module after the forward pass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Call the forward method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/module.py:203\u001b[0m, in \u001b[0;36mModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m### Step 2: Forward pass, to be implemented in the child class ###\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Call the forward method of the module\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m### Step 3: Update the output shape ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Save the input and  output shape of the module\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/architectures/transformer/self_attention.py:70\u001b[0m, in \u001b[0;36mSelfSingleHeadAttention._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(x) \u001b[38;5;66;03m# (B, S, E) -> (B, S, H)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Compute the attention scores by taking the dot product of the query and key matrices\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m scores: Tensor \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# If causal attention is enabled, we need to apply the attention mask\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcausal_attention:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Unpack the shape of the input data for better readability\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/tensor.py:279\u001b[0m, in \u001b[0;36mTensor.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    276\u001b[0m     matmul_backward_b(out_grad\u001b[38;5;241m=\u001b[39mout_grad, out_buffer\u001b[38;5;241m=\u001b[39mout_buffer, a_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Return the tensor operation with the specified forward and backward functions\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_binary_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackward_fn_a\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbackward_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackward_fn_b\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbackward_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/functional/base.py:92\u001b[0m, in \u001b[0;36mtensor_binary_op\u001b[0;34m(t1, t2, forward_fn, backward_fn_a, backward_fn_b, tensor_cls)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mFunction to create a tensor operation with automatic differentiation.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m- Tensor: Output tensor with the computed gradients.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Call the forward function\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m out_data, tape_idx \u001b[38;5;241m=\u001b[39m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Check if the gradient is required\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _NO_GRAD \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (t1\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mor\u001b[39;00m t2\u001b[38;5;241m.\u001b[39mrequires_grad):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# If no gradients are required, return the output tensor without backward\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/tensor.py:266\u001b[0m, in \u001b[0;36mTensor.__matmul__.<locals>.forward\u001b[0;34m(a_data, b_data)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(a_data: np\u001b[38;5;241m.\u001b[39mndarray, b_data: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# Compute the product of the two tensors\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatmul_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Machine-Learning-from-scratch/Deep Learning/Recurrent Neural Network (RNN)/../src/core/functional/kernel/matmul.py:18\u001b[0m, in \u001b[0;36mmatmul_forward\u001b[0;34m(a_data, b_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mMatrix multiplication kernel for forward pass.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m- np.ndarray: Output array.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Return the result of matrix multiplication\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training with early stopping\n",
    "history = model.fit(\n",
    "    X_train = X_train_norm,\n",
    "    y_train = y_train_norm,\n",
    "    X_valid = X_valid_norm,\n",
    "    y_valid = y_valid_norm,\n",
    "    epochs = epochs,\n",
    "    loss_fn = loss_fn,\n",
    "    optimizer = optimizer,\n",
    "    batch_size = batch_size,\n",
    "    metrics = [metrics.mean_absolute_error],\n",
    "    callbacks = [callbacks.EarlyStopping(monitor='val_loss', patience=10)],\n",
    "    encoder_input = X_train_norm[:batch_size],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae677f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115df94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "data_analysis.plot_history(\n",
    "    train_loss = model.history[\"loss\"], \n",
    "    valid_loss = model.history[\"val_loss\"],\n",
    "    title = \"Training and Validation Loss\",\n",
    "    xlabel = \"Epoch\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fc223",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5076789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient computation for evaluation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions_norm = model(X_test_norm, batch_size=batch_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b883acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_accuracy(pred: Tensor, true: Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Compute the directional accuracy of predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - pred: Tensor, predicted values\n",
    "    - true: Tensor, true values\n",
    "    \n",
    "    Returns:\n",
    "    - float, directional accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # If predicting volatility, check if it increases or decreases\n",
    "    if predict_volatility:\n",
    "        # Check if the predicted and true values are increasing or decreasing\n",
    "        pred_direction = (pred.to_numpy()[1:] > pred.to_numpy()[:-1]).astype(int)\n",
    "        true_direction = (true.to_numpy()[1:] > true.to_numpy()[:-1]).astype(int)\n",
    "    else:\n",
    "        # For log returns, check if the predicted and true values are positive or negative\n",
    "        pred_direction = (pred.to_numpy() > 0).astype(int)\n",
    "        true_direction = (true.to_numpy() > 0).astype(int)\n",
    "    \n",
    "    # Calculate the directional accuracy\n",
    "    accuracy = np.mean(pred_direction == true_direction)\n",
    "    \n",
    "    # Return the directional accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286731c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize the predictions using the target normalization statistics\n",
    "predictions = denormalization_fn(predictions_norm)\n",
    "\n",
    "# Compute the mean absolute error on the test set\n",
    "mae = metrics.mean_absolute_error(predictions, y_test)\n",
    "\n",
    "# Print the test results\n",
    "print(f\"Test Results:\")\n",
    "print(f\"Mean Absolute Error: {mae.to_numpy()}\")\n",
    "\n",
    "# Compute the directional accuracy\n",
    "dir_acc = directional_accuracy(predictions, y_test)\n",
    "\n",
    "# Print the directional accuracy\n",
    "print(f\"Directional Accuracy: {dir_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the plot object based on whether we are predicting volatility or log returns\n",
    "plot_obj = \"Volatility\" if predict_volatility else \"Log Returns\"\n",
    "samples_to_plot = 100  # Number of samples to plot\n",
    "\n",
    "# Sort the test timestamps and corresponding predictions and true values\n",
    "sorted_indices = np.argsort(test_timestamps.to_numpy())\n",
    "sorted_test_timestamps = test_timestamps.to_numpy()[sorted_indices]\n",
    "sorted_y_test = y_test.to_numpy()[sorted_indices]\n",
    "sorted_predictions = predictions.to_numpy()[sorted_indices]\n",
    "\n",
    "# Extract the test dates by converting timestamps to datetime\n",
    "test_dates = np.array([datetime.fromtimestamp(int(t)) for t in sorted_test_timestamps])\n",
    "\n",
    "# Create a figure for plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot the time series of true and predicted volatility\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(test_dates[-samples_to_plot:], sorted_y_test[-samples_to_plot:, close_price_idx], label=f'True {plot_obj}', alpha=0.7)\n",
    "plt.plot(test_dates[-samples_to_plot:], sorted_predictions[-samples_to_plot:, close_price_idx], label=f'Predicted {plot_obj}', alpha=0.7)\n",
    "plt.title(f'{plot_obj} Prediction Results')\n",
    "plt.ylabel(plot_obj)\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(nbins=20))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Scatter plot of true vs predicted volatility\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(y_test.to_numpy()[:, close_price_idx], predictions.to_numpy()[:, close_price_idx], alpha=0.5)\n",
    "plt.plot(\n",
    "    [y_test.to_numpy()[:, close_price_idx].min(), y_test.to_numpy()[:, close_price_idx].max()],\n",
    "    [y_test.to_numpy()[:, close_price_idx].min(), y_test.to_numpy()[:, close_price_idx].max()],\n",
    "    'r--', label='Perfect Prediction'\n",
    ")\n",
    "plt.xlabel(f'True {plot_obj}')\n",
    "plt.ylabel(f'Predicted {plot_obj}')\n",
    "plt.title('Prediction Scatter Plot')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9511aa9",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62287795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of generation steps\n",
    "num_generation_steps = 8\n",
    "\n",
    "# Select the middle index for the test set\n",
    "test_idx = len(X_test_norm.to_numpy()) // 2\n",
    "\n",
    "# Take the initial sequence and true continuation for evaluation\n",
    "initial_seq = X_test_norm[test_idx:test_idx+1]\n",
    "\n",
    "# Extract the corresponding timestamp for the test index\n",
    "test_timestamp = test_timestamps[test_idx].to_numpy()\n",
    "\n",
    "# Find the position of the test index in the sorted timestamps\n",
    "sorted_test_indices = np.argsort(test_timestamps.to_numpy())\n",
    "position_in_sorted = np.where(sorted_test_indices == test_idx)[0][0]\n",
    "\n",
    "# Take the true continuation from the test set\n",
    "if position_in_sorted + num_generation_steps <= len(sorted_test_indices):\n",
    "    consecutive_indices = sorted_test_indices[position_in_sorted:position_in_sorted + num_generation_steps]\n",
    "    true_continuation = y_test[consecutive_indices]\n",
    "else:\n",
    "    # If not enough steps are available, adjust the number of generation steps\n",
    "    available_steps = len(sorted_test_indices) - position_in_sorted\n",
    "    consecutive_indices = sorted_test_indices[position_in_sorted:position_in_sorted + available_steps]\n",
    "    true_continuation = y_test[consecutive_indices]\n",
    "    num_generation_steps = available_steps\n",
    "\n",
    "# Perform autoregressive prediction\n",
    "out_seq = model.autoregressive_generation(\n",
    "    x = initial_seq,\n",
    "    num_steps = num_generation_steps,\n",
    "    postprocess_fn = denormalization_fn\n",
    ")\n",
    "\n",
    "# Extract the generated sequence if out_seq is a generator\n",
    "generated_sequence = model.concat_generation(out_seq) if not isinstance(out_seq, Tensor) else out_seq\n",
    "\n",
    "# Extract the first batch of the generated sequence\n",
    "generated_sequence = generated_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af55cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot autoregressive results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define the steps for plotting\n",
    "steps = range(num_generation_steps)\n",
    "feature_idx = close_price_idx\n",
    "\n",
    "# Plot the true continuation and generated sequence\n",
    "plt.plot(steps, true_continuation.to_numpy()[:num_generation_steps, close_price_idx], 'b-', label='True Values', linewidth=2, marker='o')\n",
    "plt.plot(steps, generated_sequence.to_numpy()[:, close_price_idx], 'r--', label='Generated Values', linewidth=2, marker='s')\n",
    "\n",
    "# Define the plot configurations\n",
    "plt.title(f'Autoregressive Prediction - {\"Volatility\" if predict_volatility else \"Log Returns\"}')\n",
    "plt.xlabel('Prediction Steps')\n",
    "plt.ylabel(f'{\"Volatility\" if predict_volatility else \"Log Returns\"}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13209d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the autoregressive directional accuracy\n",
    "auto_dir_acc = directional_accuracy(generated_sequence[:, close_price_idx], true_continuation[:, close_price_idx])\n",
    "\n",
    "# Print the autoregressive directional accuracy\n",
    "print(f\"Autoregressive Directional Accuracy: {auto_dir_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
