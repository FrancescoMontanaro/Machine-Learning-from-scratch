{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Generator, Optional, Tuple\n",
    "from utils import build_sequences, load_txt_file\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src.models.data_loader import DataLoader, Split\n",
    "from src.models import TrainingArguments, LabeledData\n",
    "from src.core.utils import data_analysis, context_manager\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.architectures.transformer.config import TransformerConfig, DeepSeekTransformerBlockConfig, LatentAttentionConfig, MOEConfig, MLPConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'shakespeare.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer_shakespeare.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model_shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.2 # The dropout rate\n",
    "n_epochs = 30 # The number of epochs to train the model for\n",
    "max_steps_per_epoch = 100 # Number of random training steps per epoch\n",
    "max_eval_steps_per_epoch = 50 # Number of validation/test steps for faster evaluation\n",
    "max_test_samples = 256 # Number of test samples for faster evaluation\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 8 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 4 # The number of steps to accumulate gradients before updating the model\n",
    "max_sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 1e-3 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "seed = 42 # Random seed for reproducibility\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 8 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 8 # The number of transformer decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the token stream first to avoid leakage across train/valid/test\n",
    "n_tokens = len(data)\n",
    "test_tokens = max(1, int(n_tokens * train_test_split_pct))\n",
    "train_valid_tokens = n_tokens - test_tokens\n",
    "valid_tokens = max(1, int(train_valid_tokens * train_valid_split_pct))\n",
    "train_tokens = train_valid_tokens - valid_tokens\n",
    "\n",
    "# Extract the token splits\n",
    "tokens_train = data[:train_tokens]\n",
    "tokens_valid = data[train_tokens:train_tokens + valid_tokens]\n",
    "tokens_test = data[train_tokens + valid_tokens:]\n",
    "\n",
    "# Build the full sequence datasets for each split\n",
    "X_train_data, y_train_data = build_sequences(tokens_train, max_sequence_length)\n",
    "X_valid_data, y_valid_data = build_sequences(tokens_valid, max_sequence_length)\n",
    "X_test_data, y_test_data = build_sequences(tokens_test, max_sequence_length)\n",
    "\n",
    "# Convert the data to Tensors\n",
    "X_train = Tensor(X_train_data.astype(np.int32))\n",
    "y_train = Tensor(y_train_data.astype(np.int32))\n",
    "X_valid = Tensor(X_valid_data.astype(np.int32))\n",
    "y_valid = Tensor(y_valid_data.astype(np.int32))\n",
    "X_test = Tensor(X_test_data.astype(np.int32))\n",
    "y_test = Tensor(y_test_data.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (468459, 256) (468459, 256)\n",
      "Validation set: (51823, 256) (51823, 256)\n",
      "Testing set: (57610, 256) (57610, 256)\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Validation set:', X_valid.shape, y_valid.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    config = TransformerConfig(\n",
    "        input_dim = vocab_size, # The size of the input vocabulary\n",
    "        embed_dim = n_embed, # The size of the token embeddings\n",
    "        num_blocks = n_decoder_blocks, # The number of transformer blocks\n",
    "        max_sequence_length = max_sequence_length, # The length of the input sequences\n",
    "        return_sequence = True, # Return the full sequence output\n",
    "        use_cache = True, # Use caching for faster decoding during inference\n",
    "        input_type = \"discrete\", # Discrete input type for token IDs\n",
    "        positional_encoding_type = \"learned\", # Positional encoding type\n",
    "        block_config = DeepSeekTransformerBlockConfig(\n",
    "            attention_config = LatentAttentionConfig(\n",
    "                num_heads = 4, # Number of attention heads\n",
    "                dropout = 0.1, # Dropout rate\n",
    "                causal = True, # Causal attention\n",
    "                q_lora_rank = 64, # LoRA rank for query\n",
    "                qk_lora_rank = 64, # LoRA rank for query-key\n",
    "                qk_nope_head_dim = 16, # NoPE head dimension for query-key\n",
    "                qk_rope_head_dim = 16, # RoPE head dimension for query-key\n",
    "                kv_lora_rank = 32, # LoRA rank for key-value\n",
    "                v_head_dim = 32, # Head dimension for value\n",
    "                softmax_scale = 1.0 # Softmax scaling factor\n",
    "            ),\n",
    "            ffn_config = MOEConfig(\n",
    "                top_k = 2, # Top-k experts to use\n",
    "                n_groups = 1, # Number of expert groups\n",
    "                top_k_groups = 1, # Number of top-k groups\n",
    "                score_function = \"softmax\", # Scoring function for routing\n",
    "                route_scale = 1.0, # Scaling factor for routing scores\n",
    "                n_routed_experts = 4, # Number of routed experts\n",
    "                n_shared_experts = 2, # Number of shared experts\n",
    "                mlp_config = MLPConfig(\n",
    "                    dropout = 0.1, # Dropout rate\n",
    "                    hidden_dim = 256 # Hidden dimension\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(8, 256, 1024), params=15953440]\n",
      "└── language_model.modules (ModuleList) [output_shape=(8, 256, 1024), params=15953440]\n",
      "    └── module_list.0 (Decoder) [output_shape=(8, 256, 1024), params=15953440]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(8, 256, 384), params=393216]\n",
      "        ├── decoder.positional_encoding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=15066912]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1179, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1179, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1179, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1179, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1179, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(1008, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1008, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(1008, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(1008, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(1008, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(897, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(897, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(897, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(897, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(897, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(1012, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(1012, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(1012, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(1012, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(1012, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1033, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1033, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1033, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1033, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1033, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(985, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(985, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(985, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(985, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(985, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(1140, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1140, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(1140, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(1140, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(1140, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(938, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(938, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(938, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(938, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(938, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1238, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1238, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1238, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1238, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1238, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(916, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(916, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(916, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(916, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(916, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(978, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(978, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(978, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(978, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(978, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(964, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(964, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(964, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(964, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(964, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1035, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1035, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1035, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1035, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1035, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(1021, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1021, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(1021, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(1021, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(1021, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(1133, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1133, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(1133, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(1133, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(1133, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(907, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(907, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(907, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(907, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(907, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(598, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(598, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(598, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(598, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(598, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(1352, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1352, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(1352, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(1352, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(1352, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(1150, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1150, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(1150, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(1150, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(1150, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(996, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(996, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(996, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(996, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(996, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.5 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1017, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1017, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1017, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1017, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1017, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(930, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(930, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(930, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(930, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(930, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(1090, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1090, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(1090, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(1090, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(1090, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(1059, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(1059, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(1059, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(1059, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(1059, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   ├── module_list.6 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │   │   ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │   │   ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │   │   │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │   │   │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │   │   │   │   ├── module_list.0 (MLP) [output_shape=(1132, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1132, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1132, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1132, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1132, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.1 (MLP) [output_shape=(1034, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1034, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(1034, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(1034, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.1.w3 (Dense) [output_shape=(1034, 256), params=98560]\n",
      "        │   │   │   │   ├── module_list.2 (MLP) [output_shape=(952, 384), params=295808]\n",
      "        │   │   │   │   │   ├── mlp.dropout (Dropout) [output_shape=(952, 384), params=0]\n",
      "        │   │   │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(952, 256), params=98560]\n",
      "        │   │   │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(952, 384), params=98688]\n",
      "        │   │   │   │   │   └── module_list.2.w3 (Dense) [output_shape=(952, 256), params=98560]\n",
      "        │   │   │   │   └── module_list.3 (MLP) [output_shape=(978, 384), params=295808]\n",
      "        │   │   │   │       ├── mlp.dropout (Dropout) [output_shape=(978, 384), params=0]\n",
      "        │   │   │   │       ├── module_list.3.w1 (Dense) [output_shape=(978, 256), params=98560]\n",
      "        │   │   │   │       ├── module_list.3.w2 (Dense) [output_shape=(978, 384), params=98688]\n",
      "        │   │   │   │       └── module_list.3.w3 (Dense) [output_shape=(978, 256), params=98560]\n",
      "        │   │   │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │   │   │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │   │   │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │   │   │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │   │   ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   │   └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │   └── module_list.7 (Block) [output_shape=(8, 256, 384), params=1883364]\n",
      "        │       ├── block.mla (SelfMultiHeadLatentAttention) [output_shape=(8, 256, 384), params=106592]\n",
      "        │       │   ├── self_multi_head_latent_attention.wq_a (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   ├── self_multi_head_latent_attention.q_norm (RMSNorm) [output_shape=(8, 256, 64), params=64]\n",
      "        │       │   ├── self_multi_head_latent_attention.wq_b (Dense) [output_shape=(8, 256, 128), params=8192]\n",
      "        │       │   ├── self_multi_head_latent_attention.wkv_a (Dense) [output_shape=(8, 256, 48), params=18432]\n",
      "        │       │   ├── self_multi_head_latent_attention.kv_norm (RMSNorm) [output_shape=(8, 256, 32), params=32]\n",
      "        │       │   ├── self_multi_head_latent_attention.wkv_b (Dense) [output_shape=(1, 1, 192), params=6144]\n",
      "        │       │   ├── self_multi_head_latent_attention.rope (RoPE) [output_shape=(8, 256, 1, 16), params=0]\n",
      "        │       │   ├── self_multi_head_latent_attention.attn_dropout (Dropout) [output_shape=(8, 256, 4, 256), params=0]\n",
      "        │       │   ├── self_multi_head_latent_attention.proj_dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │       │   └── block.mla.wo (Dense) [output_shape=(8, 256, 384), params=49152]\n",
      "        │       ├── block.ffn_moe (MoE) [output_shape=(8, 256, 384), params=1776004]\n",
      "        │       │   ├── mo_e.gate (Gate) [output_shape=(2048, 2), params=1540]\n",
      "        │       │   ├── mo_e.routed_experts (ModuleList) [output_shape=?, params=1183232]\n",
      "        │       │   │   ├── module_list.0 (MLP) [output_shape=(1175, 384), params=295808]\n",
      "        │       │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1175, 384), params=0]\n",
      "        │       │   │   │   ├── module_list.0.w1 (Dense) [output_shape=(1175, 256), params=98560]\n",
      "        │       │   │   │   ├── module_list.0.w2 (Dense) [output_shape=(1175, 384), params=98688]\n",
      "        │       │   │   │   └── module_list.0.w3 (Dense) [output_shape=(1175, 256), params=98560]\n",
      "        │       │   │   ├── module_list.1 (MLP) [output_shape=(696, 384), params=295808]\n",
      "        │       │   │   │   ├── mlp.dropout (Dropout) [output_shape=(696, 384), params=0]\n",
      "        │       │   │   │   ├── module_list.1.w1 (Dense) [output_shape=(696, 256), params=98560]\n",
      "        │       │   │   │   ├── module_list.1.w2 (Dense) [output_shape=(696, 384), params=98688]\n",
      "        │       │   │   │   └── module_list.1.w3 (Dense) [output_shape=(696, 256), params=98560]\n",
      "        │       │   │   ├── module_list.2 (MLP) [output_shape=(1338, 384), params=295808]\n",
      "        │       │   │   │   ├── mlp.dropout (Dropout) [output_shape=(1338, 384), params=0]\n",
      "        │       │   │   │   ├── module_list.2.w1 (Dense) [output_shape=(1338, 256), params=98560]\n",
      "        │       │   │   │   ├── module_list.2.w2 (Dense) [output_shape=(1338, 384), params=98688]\n",
      "        │       │   │   │   └── module_list.2.w3 (Dense) [output_shape=(1338, 256), params=98560]\n",
      "        │       │   │   └── module_list.3 (MLP) [output_shape=(887, 384), params=295808]\n",
      "        │       │   │       ├── mlp.dropout (Dropout) [output_shape=(887, 384), params=0]\n",
      "        │       │   │       ├── module_list.3.w1 (Dense) [output_shape=(887, 256), params=98560]\n",
      "        │       │   │       ├── module_list.3.w2 (Dense) [output_shape=(887, 384), params=98688]\n",
      "        │       │   │       └── module_list.3.w3 (Dense) [output_shape=(887, 256), params=98560]\n",
      "        │       │   └── mo_e.shared_experts (MLP) [output_shape=(2048, 384), params=591232]\n",
      "        │       │       ├── mlp.dropout (Dropout) [output_shape=(2048, 384), params=0]\n",
      "        │       │       ├── mo_e.shared_experts.w1 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │       │       ├── mo_e.shared_experts.w2 (Dense) [output_shape=(2048, 384), params=196992]\n",
      "        │       │       └── mo_e.shared_experts.w3 (Dense) [output_shape=(2048, 512), params=197120]\n",
      "        │       ├── block.attn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        │       └── block.ffn_norm (RMSNorm) [output_shape=(8, 256, 384), params=384]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(8, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader for language model training\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    DataLoader with random train sampling and sequential validation batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data: LabeledData,\n",
    "        valid_data: Optional[LabeledData] = None,\n",
    "        max_train_steps_per_epoch: int = 100,\n",
    "        max_eval_steps_per_epoch: int = 25,\n",
    "        seed: int = 42\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the data loader.\n",
    "\n",
    "        Args:\n",
    "        - train_data (LabeledData): The training data.\n",
    "        - valid_data (Optional[LabeledData]): The validation data. If None, the validation split will be empty.\n",
    "        - max_train_steps_per_epoch (int): The maximum number of training steps to take per epoch. \n",
    "            This is used to limit the number of random batches sampled during training.\n",
    "        - max_eval_steps_per_epoch (int): The maximum number of evaluation steps to take per epoch for validation and testing. \n",
    "            This is used to limit the number of batches sampled during evaluation for faster evaluation.\n",
    "        - seed (int): The random seed for reproducibility when sampling batches.\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the parent constructor to initialize the data splits\n",
    "        super().__init__(train_data=train_data, valid_data=valid_data)\n",
    "\n",
    "        # Store the maximum number of steps per epoch for training and evaluation\n",
    "        self.max_train_steps_per_epoch = max_train_steps_per_epoch\n",
    "        self.max_eval_steps_per_epoch = max_eval_steps_per_epoch\n",
    "\n",
    "        # Initialize the random number generator for sampling batches\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "    def get_batch(self, split: Split, batch_size: int) -> Generator[Tuple[Tuple[Tensor, ...], Tensor], None, None]:\n",
    "        \"\"\"\n",
    "        Get a batch of data for the specified split.\n",
    "        \n",
    "        Args:\n",
    "        - split (Split): The data split to get the batch from (train, valid, or test).\n",
    "        - batch_size (int): The number of samples to include in the batch.\n",
    "        \n",
    "        Yields:\n",
    "        - Tuple[Tuple[Tensor, ...], Tensor]: A tuple containing the input tensors and the target tensor for the batch.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the data for the specified split\n",
    "        data = self._get_data_split(split)\n",
    "\n",
    "        # Determine the number of steps to take based on the split\n",
    "        num_steps = self.num_batches(split=split)\n",
    "\n",
    "        # Extract the inputs and targets from the data\n",
    "        data_inputs = data.input_tuple\n",
    "        data_targets = data.target\n",
    "\n",
    "        # Get the number of samples in the dataset\n",
    "        n_samples = data_inputs[0].shape[0]\n",
    "\n",
    "        # Iterate for the specified number of steps and yield batches of data\n",
    "        for _ in range(num_steps):\n",
    "            # Sample random indices for the batch\n",
    "            batch_indices = self._rng.integers(0, n_samples, size=batch_size)\n",
    "\n",
    "            # Create the batch of input tensors and target tensor using the sampled indices\n",
    "            x_batch = tuple(tensor[batch_indices] for tensor in data_inputs)\n",
    "            y_batch = data_targets[batch_indices]\n",
    "\n",
    "            # Yield the batch of input tensors and target tensor\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "    def num_batches(self, split: Split, *args, **kwargs) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of batches to take for the specified split.\n",
    "        \n",
    "        Args:\n",
    "        - split (Split): The data split to get the number of batches for (train, valid, or test).\n",
    "        \n",
    "        Returns:\n",
    "        - int: The number of batches to take for the specified split.\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine the number of steps to take based on the split\n",
    "        if split == Split.TRAIN:\n",
    "            return self.max_train_steps_per_epoch\n",
    "        if split == Split.VALID:\n",
    "            return self.max_eval_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 --> loss: 4.8262 | val_loss: 4.0339                                                                                                       \n",
      "Epoch 2/30 --> loss: 3.722 | val_loss: 3.692                                                                                                         \n",
      "Epoch 3/30 --> loss: 3.4481 | val_loss: 3.4712                                                                                                       \n",
      "Epoch 4/30 --> loss: 3.1308 | val_loss: 3.081                                                                                                        \n",
      "Epoch 5/30 --> loss: 2.6888 | val_loss: 2.4476                                                                                                       \n",
      "Epoch 6/30 --> loss: 2.0551 | val_loss: 1.9516                                                                                                       \n",
      "Epoch 7/30 --> loss: 1.7911 | val_loss: 1.8354                                                                                                       \n",
      "Epoch 8/30 --> loss: 1.7283 | val_loss: 1.8174                                                                                                       \n",
      "Epoch 9/30 --> loss: 1.7187 | val_loss: 1.8216                                                                                                       \n",
      "Epoch 10/30 --> loss: 1.7014 | val_loss: 1.7861                                                                                                      \n",
      "Epoch 11/30 --> loss: 1.6987 | val_loss: 1.7978                                                                                                      \n",
      "Epoch 12/30 --> loss: 1.6862 | val_loss: 1.7796                                                                                                      \n",
      "Epoch 13/30 --> loss: 1.6787 | val_loss: 1.7805                                                                                                      \n",
      "Epoch 14/30 --> loss: 1.6732 | val_loss: 1.7777                                                                                                      \n",
      "Epoch 15/30 --> loss: 1.6706 | val_loss: 1.7851                                                                                                      \n",
      "Epoch 16/30 --> loss: 1.6573 | val_loss: 1.7719                                                                                                      \n",
      "Epoch 17/30 --> loss: 1.6578 | val_loss: 1.7601                                                                                                      \n",
      "Epoch 18/30 --> loss: 1.6491 | val_loss: 1.7736                                                                                                      \n",
      "Epoch 19/30 --> loss: 1.6444 | val_loss: 1.7611                                                                                                      \n",
      "Epoch 20/30 --> loss: 1.6405 | val_loss: 1.7584                                                                                                      \n",
      "Epoch 21/30 --> loss: 1.6347 | val_loss: 1.7488                                                                                                      \n",
      "Epoch 22/30 --> loss: 1.6059 | val_loss: 1.7303                                                                                                      \n",
      "Epoch 23/30 --> loss: 1.5976 | val_loss: 1.7235                                                                                                      \n",
      "Epoch 24/30 --> loss: 1.5701 | val_loss: 1.6904                                                                                                      \n",
      "Epoch 25/30 --> loss: 1.5299 | val_loss: 1.5979                                                                                                      \n",
      "Epoch 26/30 --> loss: 1.424 | val_loss: 1.4401                                                                                                       \n",
      "Epoch 27/30 --> loss: 1.2683 | val_loss: 1.2341                                                                                                      \n",
      "Epoch 28/30 --> loss: 1.0843 | val_loss: 1.0586                                                                                                      \n",
      "Epoch 29/30 --> loss: 0.92837 | val_loss: 0.91501                                                                                                    \n",
      "Epoch 30/30 --> loss: 0.8023 | val_loss: 0.79817                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "# Create the training arguments\n",
    "train_arguments = TrainingArguments(\n",
    "    data_loader = LanguageModelDataLoader(\n",
    "        train_data = LabeledData(input={'x': X_train}, target=y_train),\n",
    "        valid_data = LabeledData(input={'x': X_valid}, target=y_valid),\n",
    "        max_train_steps_per_epoch = max_steps_per_epoch,\n",
    "        max_eval_steps_per_epoch = max_eval_steps_per_epoch,\n",
    "        seed = seed\n",
    "    ),\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    train_batch_size = batch_size,\n",
    "    num_epochs = n_epochs,\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = language_model.fit(train_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32/32 - 318.7 ms/stepp"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions_out = language_model(X_test[:max_test_samples], batch_size=batch_size, verbose=True)\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions_out.output.to_numpy(), axis=-1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:max_test_samples, -1], predictions[:, -1])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " forble,\n",
      "O, wake may, a orning bort risets:\n",
      "When you.\n",
      "Thenermilight fair cute seety triefs but can give to, afive o lov o ligum Somaltunnerve to he the hear himself ender queen chamble send me.\n",
      "Hence\n",
      "EYetered truth.\n",
      "\n",
      "Westy, much canyer'd the come?\n",
      "\n",
      "No my of me;\n",
      "Thenyeto thy, send.\n",
      "\n",
      "Pock trieveire cry; beenough, bire hadgry haven is do and, ears sasp all a could ime me, see p"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True, do_sample=True):\n",
    "    # Decode the token - use .item() to extract the scalar value\n",
    "    decoded_token = tokenizer.decode([int(token.data.item())])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
