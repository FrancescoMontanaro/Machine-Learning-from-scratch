{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the tokenizer and model files\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer_divina_commedia.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model_divina_commedia')\n",
    "\n",
    "# Define inference parameters\n",
    "prompt = 'Nel mezzo del cammin di nostra vita'\n",
    "max_new_tokens = 300\n",
    "do_sample = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the tokenizer state\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Load the trained language model\n",
    "language_model: DecoderTransformer = DecoderTransformer.load(model_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "language_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nel mezzo del cammin di nostra vita,\n",
      "Quando un letto dalundi spirto incondanno,\n",
      "ch'un monsto mozzava, e Cerro a di Taci acqua Cerranno\n",
      "punto, ch'altrimento or morte con cruccia.\n",
      "Quanto, anni, marbbattroso all'umano,\n",
      "con me la sentir lo 'l se il cred'Adigne col duca\n",
      "l'opulmollor, che nel gora lo mose\n",
      "Sanza segnosa d'essario a facea donne uso;\n",
      "e tocci fin tene\n",
      "mio, che l'occhi di misi de' andale di Brsi spaga non dico:\n",
      "si campasto chi oscura,\n",
      "ostra\n",
      "a dall' velmente n'era china e mbe tto ben sanza sopra\n",
      "furon il qual"
     ]
    }
   ],
   "source": [
    "# Encode the initial prompt\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "context = Tensor(np.array([prompt_ids], dtype=np.int32))\n",
    "\n",
    "# Print prompt\n",
    "print(prompt, end='', flush=True)\n",
    "\n",
    "# Generate and stream new tokens\n",
    "for token in language_model.autoregressive_generation(\n",
    "    x = context,\n",
    "    num_steps = max_new_tokens,\n",
    "    stream = True,\n",
    "    do_sample = do_sample\n",
    "):\n",
    "    token_id = int(np.array(token.data).reshape(-1)[0])\n",
    "    decoded_token = tokenizer.decode([token_id])\n",
    "    print(decoded_token, end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
