{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.core.utils import data_analysis, data_processing, context_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.1 # The dropout rate\n",
    "maximum_samples = 19840 # The maximum number of samples to use from the dataset\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 32 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 1 # The number of steps to accumulate gradients before updating the model\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 1e-3 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "epochs = 1 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, seq_length: int, num_samples: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - seq_length: int, length of input sequences\n",
    "    - num_samples: int, number of sequences to generate\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor], input sequences and targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y = [], []\n",
    "    n = len(input_data)\n",
    "    \n",
    "    # Iterate over the number of samples to create\n",
    "    for _ in range(num_samples):\n",
    "        # Generate a random starting index for the sequence\n",
    "        start_idx = np.random.randint(0, n - seq_length - 1)\n",
    "        \n",
    "        # Extract the input and target sequences\n",
    "        # The input sequence is the current sequence of length seq_length\n",
    "        # The target sequence is the next sequence of length seq_length (shifted by one)\n",
    "        input_sequence = input_data[start_idx : start_idx + seq_length]\n",
    "        target_sequence = input_data[start_idx + 1 : start_idx + seq_length + 1]\n",
    "        \n",
    "        # Aggiungi le sequenze alle liste\n",
    "        X.append(input_sequence)\n",
    "        y.append(target_sequence)\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return Tensor(np.array(X, dtype=np.int32)), Tensor(np.array(y, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences from the encoded text data\n",
    "X, y = build_sequences(data, sequence_length, maximum_samples)\n",
    "\n",
    "# Shuffle the data\n",
    "X_shuffled, y_shuffled = data_processing.shuffle_data((X, y))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (16071, 256) (16071, 256)\n",
      "Validation set: (1785, 256) (1785, 256)\n",
      "Testing set: (1984, 256) (1984, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data((X_shuffled, y_shuffled), train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape(), y_train.shape())\n",
    "print('Validation set:', X_valid.shape(), y_valid.shape())\n",
    "print('Testing set:', X_test.shape(), y_test.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    input_dim = vocab_size,\n",
    "    sequence_length = sequence_length,\n",
    "    n_embed = n_embed,\n",
    "    return_sequence = True,\n",
    "    n_attention_heads = n_attention_heads,\n",
    "    n_decoder_blocks = n_decoder_blocks,\n",
    "    dropout = dropout,\n",
    "    positional_encoding_type = 'learned'\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy(from_sequence=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(32, 256, 1024), params=11526400]\n",
      "└── language_model.modules (ModuleList) [output_shape=(32, 256, 1024), params=11526400]\n",
      "    └── module_list.0 (Decoder) [output_shape=(32, 256, 1024), params=11526400]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(32, 256, 384), params=393216]\n",
      "        ├── decoder.positional_encoding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=10639872]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │   │   └── module_list.4.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │   │       └── module_list.4.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        │   └── module_list.5 (Block) [output_shape=(32, 256, 384), params=1773312]\n",
      "        │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       ├── block.mlp (MLP) [output_shape=(32, 256, 384), params=1181568]\n",
      "        │       │   ├── mlp.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │       │   ├── block.mlp.input_dense (Dense) [output_shape=(32, 256, 1536), params=591360]\n",
      "        │       │   └── block.mlp.output_dense (Dense) [output_shape=(32, 256, 384), params=590208]\n",
      "        │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        │       └── module_list.5.self_attention_heads (SelfMultiHeadAttention) [output_shape=(32, 256, 384), params=590208]\n",
      "        │           ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │           │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(32, 256, 64), params=73728]\n",
      "        │           │       ├── self_single_head_attention.key (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.query (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.value (Dense) [output_shape=(32, 256, 64), params=24576]\n",
      "        │           │       └── self_single_head_attention.dropout (Dropout) [output_shape=(32, 256, 256), params=0]\n",
      "        │           ├── self_multi_head_attention.dropout (Dropout) [output_shape=(32, 256, 384), params=0]\n",
      "        │           └── module_list.5.self_attention_heads.output_linear (Dense) [output_shape=(32, 256, 384), params=147840]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(32, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(32, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 --> loss: 3.1966 - accuracy: 0.33262 | Valid loss: 3.0124 - Valid accuracy: 0.34007                        \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = language_model.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_valid = X_valid,\n",
    "    y_valid = y_valid,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    metrics = [metrics.accuracy],\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8 - 2251.76 ms/step"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions = language_model(X_test[:256], batch_size=batch_size, verbose=True)\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions.data, axis=-1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:256, -1], predictions[:, -1])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mia comessapesimigliam Cristo sua\n",
      "mezza.\n",
      "Aul'Arera Chireggi pur come rigata.\n",
      "Ma, chattentravre,\n",
      "parlar tornongiunta pio;\n",
      "ma si per loco piangogardi guarda\n",
      "che a se Pice che lor pio,\n",
      "e.\n",
      "Dio invere tri parlari si risol co,\n",
      "a il fostiemi grazia\n",
      "dellunfar levarna,\n",
      "emoltolvo'ardora popal e mino ala\n",
      "dietro strisentennel'alcun ciascun lista;\n",
      "da Al "
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
