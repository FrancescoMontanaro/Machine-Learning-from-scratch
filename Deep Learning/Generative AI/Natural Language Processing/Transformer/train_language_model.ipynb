{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from typing import cast\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src.models import TrainingArguments, LabeledData\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.core.utils import data_analysis, data_processing, context_manager\n",
    "from src.architectures.transformer.config import TransformerConfig, TransformerBlockConfig, MLPConfig, AttentionConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer_divina_commedia.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model_divina_commedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.1 # The dropout rate\n",
    "maximum_samples = 19840 # The maximum number of samples to use from the dataset\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 8 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 4 # The number of steps to accumulate gradients before updating the model\n",
    "max_sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 5e-4 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "epochs = 1 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, seq_length: int, num_samples: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - seq_length: int, length of input sequences\n",
    "    - num_samples: int, number of sequences to generate\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor], input sequences and targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y = [], []\n",
    "    n = len(input_data)\n",
    "    \n",
    "    # Iterate over the number of samples to create\n",
    "    for _ in range(num_samples):\n",
    "        # Generate a random starting index for the sequence\n",
    "        start_idx = np.random.randint(0, n - seq_length - 1)\n",
    "        \n",
    "        # Extract the input and target sequences\n",
    "        # The input sequence is the current sequence of length seq_length\n",
    "        # The target sequence is the next sequence of length seq_length (shifted by one)\n",
    "        input_sequence = input_data[start_idx : start_idx + seq_length]\n",
    "        target_sequence = input_data[start_idx + 1 : start_idx + seq_length + 1]\n",
    "        \n",
    "        # Aggiungi le sequenze alle liste\n",
    "        X.append(input_sequence)\n",
    "        y.append(target_sequence)\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return Tensor(np.array(X, dtype=np.int32)), Tensor(np.array(y, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences from the encoded text data\n",
    "X, y = build_sequences(data, max_sequence_length, maximum_samples)\n",
    "\n",
    "# Shuffle the data\n",
    "X_shuffled, y_shuffled = data_processing.shuffle_data((X, y))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (16071, 256) (16071, 256)\n",
      "Validation set: (1785, 256) (1785, 256)\n",
      "Testing set: (1984, 256) (1984, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data((X_shuffled, y_shuffled), train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Validation set:', X_valid.shape, y_valid.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    config = TransformerConfig(\n",
    "        input_dim = vocab_size,\n",
    "        embed_dim = n_embed,\n",
    "        max_sequence_length = max_sequence_length,\n",
    "        return_sequence = True,\n",
    "        input_type = \"discrete\",\n",
    "        positional_encoding_type = 'learned',\n",
    "        num_blocks = n_decoder_blocks,\n",
    "        block_config = TransformerBlockConfig(\n",
    "            attention_config = AttentionConfig(\n",
    "                num_heads = n_attention_heads,\n",
    "                dropout = dropout,\n",
    "                causal = True\n",
    "            ),\n",
    "            ffn_config = MLPConfig(\n",
    "                dropout = dropout\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy(from_sequence=True, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(8, 256, 1024), params=11526400]\n",
      "└── language_model.modules (ModuleList) [output_shape=(8, 256, 1024), params=11526400]\n",
      "    └── module_list.0 (Decoder) [output_shape=(8, 256, 1024), params=11526400]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(8, 256, 384), params=393216]\n",
      "        ├── decoder.positional_encoding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=10639872]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   │   ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   │   ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   │   ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   │   ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │   │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │   │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │   │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │   │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   │   ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   └── module_list.5 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │       ├── block.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │       │   ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │       │   │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │       │   │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │       │   │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │       │   ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │       │   └── block.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │       ├── block.ffn (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │       │   ├── mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │       │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │       │   └── block.ffn.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │       └── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(8, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 --> loss: 3.1993 | val_loss: 3.0209                                                                                                        \n"
     ]
    }
   ],
   "source": [
    "# Create the training arguments\n",
    "train_arguments = TrainingArguments(\n",
    "    train_data = LabeledData(input={'x': X_train}, target=y_train),\n",
    "    valid_data = LabeledData(input={'x': X_valid}, target=y_valid),\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    train_batch_size = batch_size,\n",
    "    num_epochs = epochs,\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = language_model.fit(train_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32/32 - 91.61 ms/step"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions = cast(Tensor, language_model(X_test[:256], batch_size=batch_size, verbose=True))\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions.data, axis=-1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:256, -1], predictions[:, -1])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adpressefente vedegnompra consieri gire vole risanta.\n",
      "sol retrovai\n",
      "contenzasi un ocace sguardosi on li vuil'ane la curamoa i,\n",
      "e l lui mondo, vidall'ar contemplo so\n",
      "nechiuma termenti mai nonore pia 'ogni;\n",
      "con e alora do in grazia sanza io viende chi consi e spir suo mi Distra veschiandoveggia None donnonvidi dell'er ma mossa urismere l ar"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True, do_sample=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
