{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src import Tensor, loss_functions, optimizers, metrics\n",
    "from src.architectures.transformer import Tokenizer, DecoderTransformer\n",
    "from src.core.utils import data_analysis, data_processing, context_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')\n",
    "tokenizer_path = os.path.join(os.getcwd(), 'checkpoints', 'tokenizer.json')\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = 0.1 # The dropout rate\n",
    "maximum_samples = 19840 # The maximum number of samples to use from the dataset\n",
    "train_test_split_pct = 0.1 # 90% of the data will be used for training, 10% for testing\n",
    "train_valid_split_pct = 0.1 # 90% of the training data will be used for training, 10% for validation\n",
    "batch_size = 8 # The number of samples to use for each batch\n",
    "grad_accumulation_steps = 8 # The number of steps to accumulate gradients before updating the model\n",
    "sequence_length = 256 # The size of the sequence length (the context window)\n",
    "learning_rate = 5e-3 # The learning rate for the optimizer\n",
    "weight_decay = 0.01 # The weight decay for the optimizer\n",
    "epochs = 1 # The number of epochs to train the model for\n",
    "n_embed = 384 # The size of the token embeddings (the dimensionality of the embeddings)\n",
    "n_attention_heads = 6 # The number of attention heads in the multi-head attention mechanism\n",
    "n_decoder_blocks = 6 # The number of transformer'decoder blocks in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a text file from the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The contents of the text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'The file \"{path}\" does not exist.')\n",
    "    \n",
    "    # Read the file\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the state of the tokenizer\n",
    "tokenizer.load(tokenizer_path)\n",
    "\n",
    "# Extract the vocabulary size\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "text = load_txt_file(dataset_path)\n",
    "\n",
    "# Encode the text using the tokenizer\n",
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "# Convert the data to a tensor\n",
    "data = np.array(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(input_data: np.ndarray, seq_length: int, num_samples: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Build sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: np.ndarray, input features\n",
    "    - seq_length: int, length of input sequences\n",
    "    - num_samples: int, number of sequences to generate\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[Tensor, Tensor], input sequences and targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to hold sequences and targets\n",
    "    X, y = [], []\n",
    "    n = len(input_data)\n",
    "    \n",
    "    # Iterate over the number of samples to create\n",
    "    for _ in range(num_samples):\n",
    "        # Generate a random starting index for the sequence\n",
    "        start_idx = np.random.randint(0, n - seq_length - 1)\n",
    "        \n",
    "        # Extract the input and target sequences\n",
    "        # The input sequence is the current sequence of length seq_length\n",
    "        # The target sequence is the next sequence of length seq_length (shifted by one)\n",
    "        input_sequence = input_data[start_idx : start_idx + seq_length]\n",
    "        target_sequence = input_data[start_idx + 1 : start_idx + seq_length + 1]\n",
    "        \n",
    "        # Aggiungi le sequenze alle liste\n",
    "        X.append(input_sequence)\n",
    "        y.append(target_sequence)\n",
    "    \n",
    "    # Convert the lists to numpy arrays and return as Tensors\n",
    "    return Tensor(np.array(X, dtype=np.int32)), Tensor(np.array(y, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences from the encoded text data\n",
    "X, y = build_sequences(data, sequence_length, maximum_samples)\n",
    "\n",
    "# Shuffle the data\n",
    "X_shuffled, y_shuffled = data_processing.shuffle_data((X, y))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (16071, 256) (16071, 256)\n",
      "Validation set: (1785, 256) (1785, 256)\n",
      "Testing set: (1984, 256) (1984, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data((X_shuffled, y_shuffled), train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data((X_train, y_train), train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Validation set:', X_valid.shape, y_valid.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the language model\n",
    "language_model = DecoderTransformer(\n",
    "    name = \"Language Model\",\n",
    "    input_dim = vocab_size,\n",
    "    sequence_length = sequence_length,\n",
    "    n_embed = n_embed,\n",
    "    return_sequence = True,\n",
    "    n_attention_heads = n_attention_heads,\n",
    "    n_decoder_blocks = n_decoder_blocks,\n",
    "    dropout = dropout,\n",
    "    positional_encoding_type = 'learned'\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = loss_functions.CrossEntropy(from_sequence=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    language_model(X_train[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model (DecoderTransformer) [output_shape=(8, 256, 1024), params=11526400]\n",
      "└── language_model.modules (ModuleList) [output_shape=(8, 256, 1024), params=11526400]\n",
      "    └── module_list.0 (Decoder) [output_shape=(8, 256, 1024), params=11526400]\n",
      "        ├── decoder.input_proj (Embedding) [output_shape=(8, 256, 384), params=393216]\n",
      "        ├── decoder.positional_encoding (Embedding) [output_shape=(256, 384), params=98304]\n",
      "        ├── decoder.decoder_blocks (ModuleList) [output_shape=?, params=10639872]\n",
      "        │   ├── module_list.0 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   └── module_list.0.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │       └── module_list.0.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   ├── module_list.1 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   └── module_list.1.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │       └── module_list.1.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   ├── module_list.2 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   └── module_list.2.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │       └── module_list.2.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   ├── module_list.3 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   └── module_list.3.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │       └── module_list.3.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   ├── module_list.4 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │   │   ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │   │   │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │   │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │   │   │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │   ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │   │   └── module_list.4.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │   │       ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │   │       │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │   │       │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │   │       │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │   │       ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │   │       └── module_list.4.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        │   └── module_list.5 (Block) [output_shape=(8, 256, 384), params=1773312]\n",
      "        │       ├── block.layer_norm_1 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │       ├── block.mlp (MLP) [output_shape=(8, 256, 384), params=1181568]\n",
      "        │       │   ├── mlp.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │       │   ├── block.mlp.input_dense (Dense) [output_shape=(8, 256, 1536), params=591360]\n",
      "        │       │   └── block.mlp.output_dense (Dense) [output_shape=(8, 256, 384), params=590208]\n",
      "        │       ├── block.layer_norm_2 (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        │       └── module_list.5.self_attention_heads (SelfMultiHeadAttention) [output_shape=(8, 256, 384), params=590208]\n",
      "        │           ├── self_multi_head_attention.heads (ModuleList) [output_shape=?, params=442368]\n",
      "        │           │   ├── module_list.0 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           │   ├── module_list.1 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           │   ├── module_list.2 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           │   ├── module_list.3 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           │   ├── module_list.4 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │   │   ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │   │   └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           │   └── module_list.5 (SelfSingleHeadAttention) [output_shape=(8, 256, 64), params=73728]\n",
      "        │           │       ├── self_single_head_attention.key (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.query (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │       ├── self_single_head_attention.value (Dense) [output_shape=(8, 256, 64), params=24576]\n",
      "        │           │       └── self_single_head_attention.dropout (Dropout) [output_shape=(8, 256, 256), params=0]\n",
      "        │           ├── self_multi_head_attention.dropout (Dropout) [output_shape=(8, 256, 384), params=0]\n",
      "        │           └── module_list.5.self_attention_heads.output_linear (Dense) [output_shape=(8, 256, 384), params=147840]\n",
      "        ├── decoder.layer_norm (LayerNormalization) [output_shape=(8, 256, 384), params=768]\n",
      "        └── decoder.output_layer (Dense) [output_shape=(8, 256, 1024), params=394240]\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary in tree format.\n",
    "# This is useful since the whole model is composed of submodules,\n",
    "# therefore, the model summary will be displayed recursively\n",
    "language_model.summary(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 --> loss: 3.1971 | Valid loss: 3.0149                                                  \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = language_model.fit(\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_valid = X_valid,\n",
    "    y_valid = y_valid,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    gradient_accumulation_steps = grad_accumulation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "language_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = language_model.history[\"loss\"], \n",
    "    valid_loss = language_model.history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Eval iter\",\n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32/32 - 2656.33 ms/step"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    language_model.eval()\n",
    "    \n",
    "    # Compute the predictions\n",
    "    predictions = language_model(X_test[:256], batch_size=batch_size, verbose=True)\n",
    "\n",
    "# Apply the argmax function to the predictions\n",
    "predictions = Tensor(np.argmax(predictions.data, axis=-1), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy = metrics.accuracy(y_test[:256, -1], predictions[:, -1])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy.data:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risetto, so  Cla lor Vir ar duna mi,\n",
      "ch'ar malin tempra E?\n",
      "LOh e luce, cid veggerau'l ma loco che Li gira chie spitte non su, ccia santo cielo allabiando vivi gio.\n",
      "La,\n",
      "per De quando fiui.\n",
      "Ro,\n",
      "se,\n",
      "Ri,\n",
      "se\n",
      "pera alcun 'mprettato spiriti.\n",
      "LE mi ita\n",
      "a e i giust'accortezza dolceati segue sanzistra'Que passi\n",
      "\n",
      "dell'l quella do tutti"
     ]
    }
   ],
   "source": [
    "# Generate some text context from the trained model\n",
    "context = Tensor(np.zeros((1, 1), dtype=np.int32))\n",
    "\n",
    "# Iterate over the tokens generated by the transformer\n",
    "for token in language_model.autoregressive_generation(x=context, num_steps=200, stream=True):\n",
    "    # Decode the token\n",
    "    decoded_token = tokenizer.decode([token.data.squeeze().tolist()])\n",
    "\n",
    "    # Print the decoded token\n",
    "    print(decoded_token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
