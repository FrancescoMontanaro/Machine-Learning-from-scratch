{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any\n",
    "\n",
    "# Add the path to the custom library to the system path\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "\n",
    "# Import the module from the custom library\n",
    "from src.architectures.sequential import Sequential\n",
    "from src.models import TrainingArguments, LabeledData\n",
    "from src.core.utils.data_processing import one_hot_encoding\n",
    "from src.architectures.auto_encoder import ConditionalVAE, VAELoss\n",
    "from src import Tensor, ModuleOutput, activations, optimizers, callbacks\n",
    "from src.core.utils import data_analysis, data_processing, context_manager\n",
    "from src.architectures.auto_encoder.config import VAEConfig, VAEEncoderConfig, VAEDecoderConfig, DenseConfig, Conv2DConfig, ConvTranspose2DConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to where the model will be saved\n",
    "model_path = os.path.join(os.getcwd(), 'checkpoints', 'conditional_variational_autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000 # Number of samples to generate\n",
    "train_test_split_pct = 0.2 # Percentage of samples to use for testing\n",
    "train_valid_split_pct = 0.2 # Percentage of samples to use for validation\n",
    "learning_rate = 1e-03 # Learning rate for the optimizer\n",
    "batch_size = 512 # Number of samples to use for each batch\n",
    "epochs = 100 # Number of epochs to train the model\n",
    "seed = 1234 # Seed for reproducibility\n",
    "data_noise = 0.15 # Noise to add to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# Add the channel dimension to the images\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Extract the number of classes in the dataset\n",
    "num_classes = len(np.unique(train_labels))    \n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X_train = Tensor(np.array(train_images))\n",
    "y_train = Tensor(np.array(train_labels), dtype=np.int8)\n",
    "X_test = Tensor(np.array(test_images))\n",
    "y_test = Tensor(np.array(test_labels), dtype=np.int8)\n",
    "\n",
    "# Split the training set into training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data(data=(X_train, y_train), split_pct=train_test_split_pct, shuffle=True)[0]\n",
    "X_train, X_valid, y_train, y_valid = data_processing.split_data(data=(X_train, y_train), split_pct=train_valid_split_pct, shuffle=True)[0]\n",
    "\n",
    "# Print the dataset information\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Validation set:', X_valid.shape, y_valid.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def normalize(X: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Normalize the input data by dividing by the maximum value in the training set.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (Tensor): The input data to normalize\n",
    "    \n",
    "    Returns:\n",
    "    - Tensor: The normalized input data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize the input data\n",
    "    return X / 255.0\n",
    "\n",
    "# Normalize the input data\n",
    "X_train = normalize(X_train)\n",
    "X_valid = normalize(X_valid)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the input data\n",
    "def add_noise(X: np.ndarray, noise: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add noise to the input data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (np.ndarray): The input data to add noise to\n",
    "    - noise (float): The noise to add to the input data\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The input data with noise added\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add noise to the input data\n",
    "    X_noisy = X + noise * np.random.normal(loc=0, scale=1.0, size=X.shape)\n",
    "    \n",
    "    # Clip the values to be between 0 and 1\n",
    "    X_noisy = np.clip(X_noisy, 0., 1.)\n",
    "    \n",
    "    # Return the noisy input data\n",
    "    return X_noisy\n",
    "\n",
    "\n",
    "# Add noise to the input data\n",
    "noise_factor = 0.6\n",
    "X_train_noisy = Tensor(add_noise(X_train.data, noise_factor))\n",
    "X_valid_noisy = Tensor(add_noise(X_valid.data, noise_factor))\n",
    "X_test_noisy = Tensor(add_noise(X_test.data, noise_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to one-hot encoding\n",
    "y_train_one_hot = one_hot_encoding(y_train, n_classes=num_classes)\n",
    "y_valid_one_hot = one_hot_encoding(y_valid, n_classes=num_classes)\n",
    "y_test_one_hot = one_hot_encoding(y_test, n_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(originale_samples: list[np.ndarray], noisy_samples: Optional[list[np.ndarray]] = None, reconstructed_samples: Optional[list[np.ndarray]] = None, labels: Optional[list[np.ndarray]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot the samples in a grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - originale_samples (list[np.ndarray]): The original samples\n",
    "    - noisy_samples (list[np.ndarray]): The noisy samples\n",
    "    - reconstructed_samples (list[np.ndarray]): The reconstructed samples\n",
    "    - labels (list[np.ndarray]): The labels of the samples\n",
    "    \"\"\"\n",
    "        \n",
    "    # Build a list of image types to plot along with their titles.\n",
    "    plot_info = [('Original', originale_samples)]\n",
    "    if noisy_samples is not None:\n",
    "        plot_info.append(('Noisy', noisy_samples))\n",
    "    if reconstructed_samples is not None:\n",
    "        plot_info.append(('Reconstructed', reconstructed_samples))\n",
    "        \n",
    "    # Get the number of rows and samples.\n",
    "    n_rows = len(plot_info)\n",
    "    n_samples = len(originale_samples)\n",
    "    \n",
    "    # Create a grid: columns = samples, rows = image types.\n",
    "    _, axes = plt.subplots(n_rows, n_samples, figsize=(n_samples * 4, n_rows * 4))\n",
    "    \n",
    "    # Ensure axes is a 2D array.\n",
    "    if n_rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0) \n",
    "    if n_samples == 1:\n",
    "        axes = np.expand_dims(axes, axis=1)\n",
    "    \n",
    "    def add_image(ax: Any, image: np.ndarray, title: str) -> None:\n",
    "        \"\"\"\n",
    "        Add an image to a subplot.\n",
    "        \n",
    "        Parameters:\n",
    "        - ax (Any): The subplot to add the image to\n",
    "        - image (np.ndarray): The image to add to the subplot\n",
    "        - title (str): The title of the subplot\n",
    "        \"\"\"\n",
    "        \n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    # Loop over rows (image types) and columns (samples).\n",
    "    for i, (title_prefix, samples) in enumerate(plot_info):\n",
    "        for j in range(n_samples):\n",
    "            # Append the label text if provided.\n",
    "            add_image(axes[i, j], samples[j], f\"{title_prefix}\\nlabel: {labels[j]}\" if labels is not None else title_prefix)\n",
    "        \n",
    "# Plot the first 10 samples\n",
    "plot_samples(\n",
    "    originale_samples = list(X_test.data[:10]),\n",
    "    noisy_samples = list(X_test_noisy.data[:10]),\n",
    "    labels = list(y_test.data[:10])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimension of the latent space\n",
    "latent_dim = 32\n",
    "\n",
    "# Initialize the Conditional Variational Autoencoder model\n",
    "conditional_vae = Sequential(\n",
    "    name = \"Conditional Variational Autoencoder\",\n",
    "    modules = [\n",
    "        ConditionalVAE(\n",
    "            num_classes = num_classes,\n",
    "            vae_config = VAEConfig(\n",
    "                encoder = VAEEncoderConfig(\n",
    "                    conv_1 = Conv2DConfig(\n",
    "                        num_filters = 32, \n",
    "                        kernel_size = (3, 3), \n",
    "                        stride = (2, 2), \n",
    "                        padding = \"same\",\n",
    "                        activation = activations.ReLU()\n",
    "                    ),\n",
    "                    conv_2 = Conv2DConfig(\n",
    "                        num_filters = 64, \n",
    "                        kernel_size = (3, 3), \n",
    "                        stride = (2, 2), \n",
    "                        padding = \"same\",\n",
    "                        activation = activations.ReLU()\n",
    "                    ),\n",
    "                    fc = DenseConfig(\n",
    "                        num_units = latent_dim, \n",
    "                        activation = activations.ReLU()\n",
    "                    )\n",
    "                ),\n",
    "                latent_dim = latent_dim,\n",
    "                decoder = VAEDecoderConfig(\n",
    "                    fc = DenseConfig(\n",
    "                        num_units = 7*7*64, \n",
    "                        activation = activations.ReLU()\n",
    "                    ),\n",
    "                    deconv_1 = ConvTranspose2DConfig(\n",
    "                        num_filters = 64, \n",
    "                        kernel_size = (3, 3), \n",
    "                        stride = (2, 2), \n",
    "                        padding = (1, 1), \n",
    "                        output_padding = (1, 1),\n",
    "                        activation = activations.ReLU()\n",
    "                    ),\n",
    "                    deconv_2 = ConvTranspose2DConfig(\n",
    "                        num_filters = 32, \n",
    "                        kernel_size = (3, 3), \n",
    "                        stride = (2, 2), \n",
    "                        padding = (1, 1), \n",
    "                        output_padding = (1, 1),\n",
    "                        activation = activations.ReLU()\n",
    "                    ),\n",
    "                    deconv_3 = ConvTranspose2DConfig(\n",
    "                        num_filters = 1, \n",
    "                        kernel_size = (3, 3), \n",
    "                        stride = (1, 1), \n",
    "                        padding = (1, 1), \n",
    "                        activation = activations.Sigmoid()\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "# Initialize the loss function with KL annealing\n",
    "# beta=1.0 is the final value, annealing_epochs=30 means beta will linearly increase from 0 to 1.0 over 30 epochs\n",
    "# This allows the model to first learn reconstruction, then gradually regularize the latent space\n",
    "loss_fn = VAELoss(beta=1.0, annealing_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model with a first batch to initialize the weights\n",
    "# This is not necessary, but it is useful to know the input size\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    conditional_vae.eval()\n",
    "    \n",
    "    # Call the model with a batch of data to initialize it\n",
    "    conditional_vae(X_train[:batch_size], y=y_train_one_hot[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the encoder summary\n",
    "conditional_vae.modules[0].encoder.summary()\n",
    "\n",
    "# Display the decoder summary\n",
    "conditional_vae.modules[0].decoder.summary()\n",
    "\n",
    "# Display the model summary\n",
    "conditional_vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "train_arguments = TrainingArguments(\n",
    "    train_data = LabeledData(input={'x': X_train_noisy, 'y': y_train_one_hot}, target=X_train),\n",
    "    valid_data = LabeledData(input={'x': X_valid_noisy, 'y': y_valid_one_hot}, target=X_valid),\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    train_batch_size = batch_size,\n",
    "    num_epochs = epochs,\n",
    "    callbacks = [callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = conditional_vae.fit(train_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "conditional_vae.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "data_analysis.plot_history(\n",
    "    train_loss = history[\"loss\"], \n",
    "    valid_loss = history[\"val_loss\"], \n",
    "    title = \"Training and Validation Loss\", \n",
    "    xlabel = \"Epoch\", \n",
    "    ylabel = \"Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    conditional_vae.eval()\n",
    "\n",
    "    # Denoise the test set\n",
    "    X_test_out = conditional_vae(\n",
    "        x = X_test_noisy,\n",
    "        y = y_test_one_hot,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "\n",
    "# Reshape the denoised test set\n",
    "X_test_denoised = X_test_out.output.reshape((-1, *X_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 10 samples\n",
    "plot_samples(\n",
    "    originale_samples = list(X_test.data[:10]),\n",
    "    noisy_samples = list(X_test_noisy.data[:10]),\n",
    "    reconstructed_samples = list(X_test_denoised.data[:10]),\n",
    "    labels = list(y_test.data[:10])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of random images to generate\n",
    "n_images = 10\n",
    "\n",
    "# Generate n random images (noise)\n",
    "random_images = np.random.rand(n_images, *X_train.shape[1:])\n",
    "random_images = Tensor(add_noise(random_images, noise_factor))\n",
    "\n",
    "# Generate the corresponding labels for the random images (random integers between 0 and num_classes-1)\n",
    "random_labels = np.random.randint(0, num_classes, size=(n_images,))\n",
    "random_labels_one_hot = one_hot_encoding(Tensor(random_labels), n_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of denoise steps\n",
    "denoise_steps = 10\n",
    "\n",
    "# Create a list to store the denoised images\n",
    "denoised_images = [random_images.reshape((-1, *X_train.shape[1:]))]\n",
    "\n",
    "# Disable gradient computation\n",
    "with context_manager.no_grad():\n",
    "    # Set the model in evaluation mode\n",
    "    conditional_vae.eval()\n",
    "    \n",
    "    # Iterate over the denoise steps\n",
    "    for i in range(denoise_steps):\n",
    "        # Get the output of the previous step (or the original random images for the first step)\n",
    "        step_input = random_images.output if isinstance(random_images, ModuleOutput) else random_images\n",
    "        \n",
    "        # Denoise the random images using the autoencoder\n",
    "        random_images = conditional_vae(step_input, y=random_labels_one_hot)\n",
    "\n",
    "        # Add the denoised images to the list\n",
    "        denoised_images.append(random_images.output.reshape((-1, *X_train.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the denoised images\n",
    "plt.figure(figsize=(2*n_images, 2*len(denoised_images)))\n",
    "for i, images in enumerate(denoised_images):\n",
    "    for j, image in enumerate(images.data):\n",
    "        plt.title(f'Sample {j}\\nLabel: {random_labels[j]}' if i == 0 else f'Denoise step {i}')\n",
    "        plt.subplot(len(denoised_images), n_images, i * n_images + j + 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
